[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ENVS543.2024",
    "section": "",
    "text": "Preface\nThis text is constructed from the narrative documents that supported each learning module in the ENVS 543 Environmental Data Literacy course taught at Virginia Commonwealth University in the Fall of 2024.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "markdown_narrative.html",
    "href": "markdown_narrative.html",
    "title": "1  Markdown",
    "section": "",
    "text": "2 Impetus\nIn current data analytics and communication, there are a wide variety of platforms on which we can provide summaries and insights regarding our work. Each of these end points requires a non-insignificant amount of effort to learn these systems. Moreover, they all are cul de sacs in that all the effort you exert to learn one will not allow you to get the benefits of any other platform than the one you just learned.\nEnter Pandoc, the universal document converter. Some really smart programmers have put together a set of software that allows you to convert from or two (and hence between) different document types given that most documents are regularly structured. With Pandoc, it does not matter if you do or do not have Word or Powerpoint or EPub or LaTeX or whatever, as long as you can create one of the supported types, you can convert that input into a huge variety of output types.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Markdown</span>"
    ]
  },
  {
    "objectID": "markdown_narrative.html#pandoc-supported-conversions",
    "href": "markdown_narrative.html#pandoc-supported-conversions",
    "title": "1  Markdown",
    "section": "2.1 Pandoc Supported Conversions",
    "text": "2.1 Pandoc Supported Conversions\n\n\n\nConversion Formats\n\n\nThis is critical for us because Code is just text. Once it is evaluated, it can replaced with:\n\nNumerical values from one or more calculations,\nTextual content from analyses or manipulation, or\nGraphical content from plots.\n\nAs such, we can embed R code within raw text to create our analyses and documents.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Markdown</span>"
    ]
  },
  {
    "objectID": "markdown_narrative.html#text-markup",
    "href": "markdown_narrative.html#text-markup",
    "title": "1  Markdown",
    "section": "4.1 Text Markup",
    "text": "4.1 Text Markup\nWhen we make a document, presentation, or any other output, there are only a finite set of different text components we can put into the document. The document itself does not need to be heavy or bloated, it is just text (though surprisingly, a blank Word document on my laptop with nothing in the document itself is still 12KB in size!). Common elements include:\n\nHeaders & Titles\nTypography such as italic, bold, underline, strike through\nLists (numbered or as bullets)\nPictures and links\nPage numbers, tables of contents, etc.\n\nWhat Markdown does is allows you to type these components and use ‘marking’ around the elements to make them different from regular text. It is really, amazingly simple.\nTitle and headers are created by prepending a hashtag\n# Header 1\n## Header 2\n### Header 3\n#### Header 4\nare knit into the following headers styles.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Markdown</span>"
    ]
  },
  {
    "objectID": "markdown_narrative.html#header-2",
    "href": "markdown_narrative.html#header-2",
    "title": "1  Markdown",
    "section": "5.1 Header 2",
    "text": "5.1 Header 2\n\n5.1.1 Header 3\n\n5.1.1.1 Header 4\nThe actual appearance of the headers are determined by where it is being presented (e.g., in Word it will take the default typography and font attributes, etc.).\nIn text markdown examples are shown below and are contained within paragraphs of text. Individual paragraphs are delimited by either a blank line between them or two spaces at the end of the sentence.\n\n\n\nMarkdown\nRendered As\n\n\n\n\nplain text\nplain text\n\n\n*italic*\nitalic\n\n\n**bold**\nbold\n\n\n~~strike through~~\nstrike through\n\n\n\nYou can also embed links and images. Both of these are configured in two parts. For links, you need to specify the text that can be clicked upon and it must be surrounded in square brackets. The link to the web or file or image is right next to the square brackets and is contained within parentheses. The difference between link and image is that images have alternative text (or at times captions) and the whole thing has an exclamation mark in front of it. Here are some examples.\n\n\n\nMarkdown\nRendered As\n\n\n\n\n[CES](https://ces.vcu.edu)\nCES\n\n\n![Goat](https://live.staticflickr.com/2417/2278662416_7683abd2d4_n_d.jpg)\n\n\n\n\nLists (both numbered and unordered) are created using dashes or asterisks.\n\nBullet 1\n\nBullet 2\n\nBullet 3\n\nWill be turned into an unordered list as:\n\nBullet 1\n\nBullet 2\n\nBullet 3\n\nWhereas the following raw text.1\n1. First\n1. Second\n1. Third\nWill be rendered in list format as:\n\nFirst\n\nSecond\n\nThird\n\nActually, you can just use 1. in front of every line if you like, it will auto-number them for you when it makes a list. I tend to do this because it makes it a bit easier in case I want to reorder the list later and I don’t have to go back and change the numbers.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Markdown</span>"
    ]
  },
  {
    "objectID": "markdown_narrative.html#code-text",
    "href": "markdown_narrative.html#code-text",
    "title": "1  Markdown",
    "section": "5.2 Code & Text",
    "text": "5.2 Code & Text\nOn of the strengths of RMarkdown is the ability to mix code and text together in one place. This allows us to bring all of our analyses and data as close to one another as possible, helping with reproducibility and error reduction.\n\n5.2.1 Inline Code\nYou can easily integrate code, into the text, either to be displayed OR to be evaluated. For example, in R you get the value of \\(\\pi\\) by the constant pi. Type that into the console and it will return 3.1415927.\nIf you look at the RMarkdown for that paragraph above, it looks like the following before knitting:\nYou can easily integrate code, into the text, either to be displayed *OR* to be evaluated.  For example, in `R` you get the value of $\\pi$ by the constant `pi`. Type that into the console and it will return 3.1415927.\nNotice the following parts:\n\nSymbols: The \\(\\pi\\) symbol is created by the name of the symbol surrounded by dollar signs. $ $. There are a ton of symbols and equations you can use, all borrowed from LaTeX, so if you need complicated equations or symbols, this is not a problem.\nText rendered as code (in typography) but not evaluated: Both the `R` and the `pi` are examples here. Nothing is evaluated, but it looks like code.\nEvaluated R Code: Any code between \\rand`will be evaluated as R code within the text. When you knit the document, it will be run and the contents between the`rand`are replaced by the output of theRcode. The example here was \\pi` at the end of the last sentence.\n\n\n\n5.2.2 Code Chunks\nIn addition to code within the text, RMarkdown supports code chunks, which can be one or many lines of raw R code. This code is executed and the results are merged into the markdown in the document (text, graphical, interactive widgets, whatever) before knitting.\nEach chunk is enclosed within boundary rows, the top row must contain three acute accents (back ticks - `) followed by the letter r in curly brackets ```{r}. The end of the chunk is indicated by three back ticks on their own line such as ```. Everything between these two enclosing lines is treated as R code and is subject to evaluation when you re-knit the document.\nHere is what a chunk looks like in markdown that prints out a simple message “This is text from a chunk.\n```{r}\nprint(“This is text from a chunk”)\n```\nWhen it is evaluated, the R interpreter removes the first and last rows, and executes the code within them. By default, the code is presented as a box in the output as well as any output that is produced from the code.\n\nprint(\"This is text from a chunk\")\n\n[1] \"This is text from a chunk\"\n\n\nThe first line in the chunk can also be used to modify the behavior of the code. There are several options that you can place within the curly brackets, including:\n\n{r eval=FALSE}: Will not evaluate (e.g., run) the code. The default value is TRUE.\n\n{r echo=FALSE}: Will not show the code in the document. This is great for our final version of our analyses, we want the output but not the code chunks showing. The default value is TRUE.\n\n{r message=FALSE, warning=FALSE, error=FALSE}: These suppress the messages that R prints out on occasion.\n\nSee the reference guide for several more options you can put into the header of each chunk.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Markdown</span>"
    ]
  },
  {
    "objectID": "markdown_narrative.html#code-chunks-in-document",
    "href": "markdown_narrative.html#code-chunks-in-document",
    "title": "1  Markdown",
    "section": "5.3 Code Chunks in Document",
    "text": "5.3 Code Chunks in Document\nThere are some very fundamental issues regarding chunks, the R environment, and documents that should be pointed out here.\n\nThe R environment (see tab labeled Environment in the RStudio interface) has all the variables and new functions that you have created listed and available for use.\nAn R Markdown document is not a ‘living’ environment. If you make a change in a chunk, you must rerun that chunk to have the output available and inserted into the Environment. It does not do it automagically.\nWhen you knit a document, the only data it has is what is actually in the document itself. It does not look to the general Environment for variables and functions. This means that if you create a variable or load data using the Console and then reference it in the Document, it will fail when you try to knit the document.\nAll the code and variables in a document (if they are not within a chunk with eval=FALSE) is visible to everything in the document below where it was defined.\n\nChunks are evaluated from the top of the document to the bottom of the document.\n\nThe options for each chunk are available from the setup menu on the top right of the chunk itself (the gear icon). Additional options include a button to run all the chunks prior to this one as well as running this particular chunk (see image).\n\n\n\n\nOption buttons for each chunk include a quick menu for optoins (gear), the ability to run all the chunks above this one (triangle and line button in the middle), and run this particular chunk (play button).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Markdown</span>"
    ]
  },
  {
    "objectID": "markdown_narrative.html#footnotes",
    "href": "markdown_narrative.html#footnotes",
    "title": "1  Markdown",
    "section": "",
    "text": "This is a footnote and is defined by enclosing square brackets and a carat symbol (^) where you want to put the footnote in the text (e.g., [^1]) and then at the bottom of the document add the text (this part) prepended by [^1]:. The linking to the footnote and back to the place you put it will be automagically inserted.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Markdown</span>"
    ]
  },
  {
    "objectID": "basic_data_narrative.html",
    "href": "basic_data_narrative.html",
    "title": "2  Basic Data Types",
    "section": "",
    "text": "2.1 Missing Data\nThe most fundamental type of data in R is data that does not exist! Missing data! It is represented as NA\nx &lt;- NA\nand can be in",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Data Types</span>"
    ]
  },
  {
    "objectID": "basic_data_narrative.html#missing-data",
    "href": "basic_data_narrative.html#missing-data",
    "title": "2  Basic Data Types",
    "section": "",
    "text": "The Absence of Data",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Data Types</span>"
    ]
  },
  {
    "objectID": "basic_data_narrative.html#numerical-data",
    "href": "basic_data_narrative.html#numerical-data",
    "title": "2  Basic Data Types",
    "section": "2.2 Numerical Data",
    "text": "2.2 Numerical Data\n\nNumerical data contains all numerical represenations.\n\nBy far, the most common kind of data we use in our analyses is numerical data. This may represent measured things like height, snout-vent length (whatever that is), depth, age, etc. In data analysis, we commonly take (or obtain) measurements from several items and then try to characterize them using summaries and visualization.\nIn R, the numerical data type can be defined as:\n\nX &lt;- 42\n\nNotice how the numerical value of 42 is assigned to the variable named X. To have R print out the value of a particular variable, you can type its name in the console and it will give it to you.\n\nX\n\n[1] 42\n\n\n\n2.2.1 Operators\nNumeric types have a ton of normal operators that can be used. Some examples include:\nThe usual arithmetic operators:\n\nx &lt;- 10\ny &lt;- 23\n\nx + y\n\n[1] 33\n\nx - y\n\n[1] -13\n\nx * y\n\n[1] 230\n\nx / y\n\n[1] 0.4347826\n\n\nYou have the exponential:\n\n## x raised to the y\nx^y\n\n[1] 1e+23\n\n## the inverse of an exponent is a root, here is the 23rd root of 10\nx^(1/y)\n\n[1] 1.105295\n\n\nThe logarithmic:\n\n## the natural log\nlog(x)\n\n[1] 2.302585\n\n## Base 10 log\nlog(x,base=10)\n\n[1] 1\n\n\nAnd the modulus operator:\n\ny %% x\n\n[1] 3\n\n\nIf you didn’t know what this one is, don’t worry. The modulus is just the remainder after division like you did in grade school. The above code means that 23 divided by 10 has a remainder of 3. I include it here just to highlight the fact that many of the operators that we will be working with in R are created by more than just a single symbol residing at the top row of your computer keyboard. There are just too few symbos on the normal keyboard to represent the breath of operators. The authors of R have decided that using combinations of symbols to handle these and you will get used to them in not time at all.\n\n\n2.2.2 Introspection & Coercion\nThe class() of a numeric type is (wait for it)… numeric (those R programmers are sure clever).\n\nclass( 42 )\n\n[1] \"numeric\"\n\n\n\nIn this case class is the name of the function and there are one or more things we pass to that function. These must be enclosed in the parenthesis associated with class. The parantheses must be right next to the name of the function. If you put a space betwen the word class and the parentheses, it may not work the way you would like it to. You’ve been warned.\nThe stuff inside the parenthesis are called arguments and are the data that we pass to the function itself. In this case we pass a value or varible to the class function and it does its magic and tells us what kind of data type it is. Many functions have several arguements that can be passed to them, some optional, some not. We will get more into that on the lecture covering Functions.\n\nIt is also possible to inquire if a particular variable is of a certain class. This is done by using the is.* set of functions.\n\nis.numeric( 42 )\n\n[1] TRUE\n\nis.numeric( \"dr dyer\" )\n\n[1] FALSE\n\n\nSometimes we may need to turn one kind of class into another kind. Consider the following:\n\nx &lt;- \"42\"\nis.numeric( x )\n\n[1] FALSE\n\nclass(x)\n\n[1] \"character\"\n\n\nIt is a character data type because it is enclosed within a set of quotes. However, we can coerce it into a numeric type by:\n\ny &lt;- as.numeric( x )\nis.numeric( y )\n\n[1] TRUE\n\ny\n\n[1] 42",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Data Types</span>"
    ]
  },
  {
    "objectID": "basic_data_narrative.html#character-data",
    "href": "basic_data_narrative.html#character-data",
    "title": "2  Basic Data Types",
    "section": "2.3 Character Data",
    "text": "2.3 Character Data\n\nCharacter data represents textual content.\n\nThe data type character is intended to represent textual data such as actual texts, names of objects, and other contnet that is intended to help both you and the audience you are trying to reach better understand your data.\n\nname &lt;- \"Dyer\"\nsport &lt;- \"Frolf\"\n\nThe two variables above have a sequence of characters enclosed by a double quote. You can use a single quote instead, however the enclosing quoting characters must be the same (e.g., you cannot start with a single quote and end with a double).\n\n2.3.1 Lengths\nThe length of a string is a measure of how many varibles there are, not the number of characters within it. For example, the length of dyer is\n\nlength(name)\n\n[1] 1\n\n\nbecause it only has one character but the number of characters within it is:\n\nnchar(name)\n\n[1] 4\n\n\nLength is defined specifically on the number of elements in a vector, and technically the variable dyer is a vector of length one. If we concatinate them into a vector (go see the vector content)\n\nphrase &lt;- c( name, sport )\n\nwe find that it has a length of 2\n\nlength(phrase)\n\n[1] 2\n\n\nAnd if we ask the vector how many characters are in the elements it contains, it gives us a vector of numeric types representing the number of letters in each of the elements.\n\nnchar(phrase)\n\n[1] 4 5\n\n\n\n\n2.3.2 Putting Character Objects Together\nThe binary + operator has not been defined for objects of class character, which is understandable once we consider all the different ways we may want to put the values contained in the variables together. If you try it, R will complain.\n\nname + sport\n\nError in name + sport: non-numeric argument to binary operator\n\n\nThe paste() function is designed to take a collection of character variables and smush them togethers. By default, it inserts a space between each of the variables and/or values passed to it.\n\npaste( name, \"plays\", sport )\n\n[1] \"Dyer plays Frolf\"\n\n\nAlthough, you can have any kind of separator you like:\n\npaste(name, sport, sep=\" is no good at \")\n\n[1] \"Dyer is no good at Frolf\"\n\n\nThe elements you pass to paste() do not need to be held in variables, you can put quoted character values in there as well.\n\npaste( name, \" the \", sport, \"er\", sep=\"\") \n\n[1] \"Dyer the Frolfer\"\n\n\nIf you have a vector of character types, by default, it considers the pasting operation to be applied to every element of the vector.\n\npaste( phrase , \"!\")\n\n[1] \"Dyer !\"  \"Frolf !\"\n\n\nHowever if you intention is to take the elements of the vector and paste them together, then you need to specify that using the collapse optional argument. By default, it is set to NULL, and that state tells the function to apply the paste()-ing to each element. However, if you set collapse to something other than NULL, it will use that to take all the elements and put them into a single response.\n\npaste( phrase, collapse = \" is not good at \") \n\n[1] \"Dyer is not good at Frolf\"\n\n\n\n\n2.3.3 String Operations\nMany times, we need to extract components from within a longer character element. Here is a longer bit of text as an example.\n\ncorpus &lt;- \"An environmental impact statement (EIS), under United States environmental law, is a document required by the 1969 National Environmental Policy Act (NEPA) for certain actions 'significantly affecting the quality of the human environment'.[1] An EIS is a tool for decision making. It describes the positive and negative environmental effects of a proposed action, and it usually also lists one or more alternative actions that may be chosen instead of the action described in the EIS. Several U.S. state governments require that a document similar to an EIS be submitted to the state for certain actions. For example, in California, an Environmental Impact Report (EIR) must be submitted to the state for certain actions, as described in the California Environmental Quality Act (CEQA). One of the primary authors of the act is Lynton K. Caldwell.\"\n\n\n\n2.3.4 Splits\nWe can split the original string into several components by specifying which particular character or set of characters we wish to use to break it apart.\nAs we start working with increasingly more complicated string operations, I like to use a higher-level library (part of tidyverse) called stringr. If you do not have this library already installed, you can install it using install.packages(\"stringr\").\n\nlibrary( stringr )\n\nHere is an example using the space character to pull it apart into words.\n\nstr_split( corpus, pattern=\" \", simplify=TRUE)\n\n     [,1] [,2]            [,3]     [,4]        [,5]     [,6]    [,7]    \n[1,] \"An\" \"environmental\" \"impact\" \"statement\" \"(EIS),\" \"under\" \"United\"\n     [,8]     [,9]            [,10]  [,11] [,12] [,13]      [,14]      [,15]\n[1,] \"States\" \"environmental\" \"law,\" \"is\"  \"a\"   \"document\" \"required\" \"by\" \n     [,16] [,17]  [,18]      [,19]           [,20]    [,21] [,22]    [,23]\n[1,] \"the\" \"1969\" \"National\" \"Environmental\" \"Policy\" \"Act\" \"(NEPA)\" \"for\"\n     [,24]     [,25]     [,26]            [,27]       [,28] [,29]     [,30]\n[1,] \"certain\" \"actions\" \"'significantly\" \"affecting\" \"the\" \"quality\" \"of\" \n     [,31] [,32]   [,33]              [,34] [,35] [,36] [,37] [,38]  [,39]\n[1,] \"the\" \"human\" \"environment'.[1]\" \"An\"  \"EIS\" \"is\"  \"a\"   \"tool\" \"for\"\n     [,40]      [,41]     [,42] [,43]       [,44] [,45]      [,46] [,47]     \n[1,] \"decision\" \"making.\" \"It\"  \"describes\" \"the\" \"positive\" \"and\" \"negative\"\n     [,48]           [,49]     [,50] [,51] [,52]      [,53]     [,54] [,55]\n[1,] \"environmental\" \"effects\" \"of\"  \"a\"   \"proposed\" \"action,\" \"and\" \"it\" \n     [,56]     [,57]  [,58]   [,59] [,60] [,61]  [,62]         [,63]     [,64] \n[1,] \"usually\" \"also\" \"lists\" \"one\" \"or\"  \"more\" \"alternative\" \"actions\" \"that\"\n     [,65] [,66] [,67]    [,68]     [,69] [,70] [,71]    [,72]       [,73]\n[1,] \"may\" \"be\"  \"chosen\" \"instead\" \"of\"  \"the\" \"action\" \"described\" \"in\" \n     [,74] [,75]  [,76]     [,77]  [,78]   [,79]         [,80]     [,81]  [,82]\n[1,] \"the\" \"EIS.\" \"Several\" \"U.S.\" \"state\" \"governments\" \"require\" \"that\" \"a\"  \n     [,83]      [,84]     [,85] [,86] [,87] [,88] [,89]       [,90] [,91]\n[1,] \"document\" \"similar\" \"to\"  \"an\"  \"EIS\" \"be\"  \"submitted\" \"to\"  \"the\"\n     [,92]   [,93] [,94]     [,95]      [,96] [,97]      [,98] [,99]        \n[1,] \"state\" \"for\" \"certain\" \"actions.\" \"For\" \"example,\" \"in\"  \"California,\"\n     [,100] [,101]          [,102]   [,103]   [,104]  [,105] [,106] [,107]     \n[1,] \"an\"   \"Environmental\" \"Impact\" \"Report\" \"(EIR)\" \"must\" \"be\"   \"submitted\"\n     [,108] [,109] [,110]  [,111] [,112]    [,113]     [,114] [,115]     \n[1,] \"to\"   \"the\"  \"state\" \"for\"  \"certain\" \"actions,\" \"as\"   \"described\"\n     [,116] [,117] [,118]       [,119]          [,120]    [,121] [,122]   \n[1,] \"in\"   \"the\"  \"California\" \"Environmental\" \"Quality\" \"Act\"  \"(CEQA).\"\n     [,123] [,124] [,125] [,126]    [,127]    [,128] [,129] [,130] [,131]\n[1,] \"One\"  \"of\"   \"the\"  \"primary\" \"authors\" \"of\"   \"the\"  \"act\"  \"is\"  \n     [,132]   [,133] [,134]     \n[1,] \"Lynton\" \"K.\"   \"Caldwell.\"\n\n\nwhich shows 134 words in the text.\nI need to point out that I added the simplify=TRUE option to str_split. Had I not done that, it would have returned a list object that contained the individual vector of words. There are various reasons that it returns a list, none of which I can frankly understand, that is just the way the authors of the function made it.\n\n\n2.3.5 Substrings\nThere are two different things you may want to do with substrings; find them and replace them. Here are some ways to figure out where they are.\n\nstr_detect(corpus, \"Environment\")\n\n[1] TRUE\n\n\n\nstr_count( corpus, \"Environment\")\n\n[1] 3\n\n\n\nstr_locate_all( corpus, \"Environment\")\n\n[[1]]\n     start end\n[1,]   125 135\n[2,]   637 647\n[3,]   754 764\n\n\nWe can also replace instances of one substring with another.\n\nstr_replace_all(corpus, \"California\", \"Virginia\")\n\n[1] \"An environmental impact statement (EIS), under United States environmental law, is a document required by the 1969 National Environmental Policy Act (NEPA) for certain actions 'significantly affecting the quality of the human environment'.[1] An EIS is a tool for decision making. It describes the positive and negative environmental effects of a proposed action, and it usually also lists one or more alternative actions that may be chosen instead of the action described in the EIS. Several U.S. state governments require that a document similar to an EIS be submitted to the state for certain actions. For example, in Virginia, an Environmental Impact Report (EIR) must be submitted to the state for certain actions, as described in the Virginia Environmental Quality Act (CEQA). One of the primary authors of the act is Lynton K. Caldwell.\"\n\n\nThere is a lot more fun stuff to do with string based data.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Data Types</span>"
    ]
  },
  {
    "objectID": "basic_data_narrative.html#logical-data",
    "href": "basic_data_narrative.html#logical-data",
    "title": "2  Basic Data Types",
    "section": "2.4 Logical Data",
    "text": "2.4 Logical Data\nLogical data consists of two mutually exclusive states: TRUE or FALSE\n \n\ndyer_has_good_jokes &lt;- TRUE\ndyer_has_good_jokes\n\n[1] TRUE\n\n\n\n2.4.1 Operators on Logical Types\nThere are 3 primary logical operators that can be used on logical types; one unary and two binary.\n \n\n2.4.1.1 Unary Operator\nThe negation operator\n\n!dyer_has_good_jokes\n\n[1] FALSE\n\n\n \n\n\n\n2.4.2 The Binary Operators\n\n2.4.2.1 The OR operator\n\nTRUE | FALSE\n\n[1] TRUE\n\n\n\n\n2.4.2.2 The AND operator\n\nTRUE & FALSE\n\n[1] FALSE\n\n\n\n\n\n2.4.3 Introspection\nLogical types have an introspection operator.\n \n\nis.logical( dyer_has_good_jokes )\n\n[1] TRUE\n\n\nCoercion of something else to a Logical is more case-specific.\nFrom character data.\n\nas.logical( \"TRUE\" )\n\n[1] TRUE\n\n\n \n\nas.logical( \"FALSE\" )\n\n[1] FALSE\n\n\nOther character types result in NA (missing data).\n\nas.logical( \"Bob\" )\n\n[1] NA\n\n\n\n\n2.4.4 Coercion\nCoercion of something else to a Logical is more case-specific.\n \nFrom numeric data:\n- Values of 0 are FALSE\n- Non-zero values are TRUE\n\nas.logical(0)\n\n[1] FALSE\n\n\n\nas.logical( 323 )\n\n[1] TRUE",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Data Types</span>"
    ]
  },
  {
    "objectID": "basic_data_narrative.html#dates",
    "href": "basic_data_narrative.html#dates",
    "title": "2  Basic Data Types",
    "section": "2.5 Dates",
    "text": "2.5 Dates\n\nTime is the next dimension.\n\nThis topic covers the basics of how we put together data based upone date and time objects. For this, we will use the following data frame with a single column of data representing dates as they are written in the US.\nThese are several challenges associated with working with date and time objects. To those of us who are reading this with a background of how US time and date formats are read, we can easily interpret data objects as Month/Day/Year formats (e.g., “2/14/2018”), and is commonly represented in the kind of input data we work in R with as with a string of characters. Dates and times are sticky things in data analysis because they do not work the way we think they should. Here are some wrinkles:\n\nThere are many types of calendars, we use the Julian calendar. However, there are many other calendars that are in use that we may run into. Each of these calendars has a different starting year (e.g., in the Assyrian calendar it is year 6770, it is 4718 in the Chinese calendar, 2020 in the Gregorian, and 1442 in the Islamic calendar).\nWestern calendar has leap years (+1 day in February) as well as leap seconds because it is based on the rotation around the sun, others are based upon the lunar cycle and have other corrections.\nOn this planet, we have 24 different time zones. Some states (looking at you Arizona) don’t feel it necessary to follow the other states around so they may be the same as PST some of the year and the same as MST the rest of the year. The provence of Newfoundland decided to be half-way between time zones so they are GMT-2:30. Some states have more than one time zone even if they are not large in size (hello Indiana).\nDates and time are made up of odd units, 60-seconds a minute, 60-minutes an hour, 24-hours a day, 7-days a week, 2-weeks a fortnight, 28,29,30,or 31-days in a month, 365 or 366 days in a year, 100 years in a century, etc.\n\nFortunately, some smart programmers have figured this out for us already. What they did is made the second as the base unit of time and designated 00:00:00 on 1 January 1970 as the unix epoch. Time on most modern computers is measured from that starting point. It is much easier to measure the difference between two points in time using the seconds since unix epich and then translate it into one or more of these calendars than to deal with all the different calendars each time. So under the hood, much of the date and time issues are kept in terms of epoch seconds.\n\nunclass( Sys.time() )\n\n[1] 1733252388\n\n\n\n2.5.1 Basic Date Objects\nR has some basic date functionality built into it. One of the easiest says to get a date object created is to specify the a date as a character string and then coerce it into a data object. By default, this requires us to represent the date objects as “YEAR-MONTH-DAY” with padding 0 values for any integer of month or date below 9 (e.g., must be two-digits).\nSo for example, we can specify a date object as:\n\nclass_start &lt;- as.Date(\"2021-01-15\")\nclass_start\n\n[1] \"2021-01-15\"\n\n\nAnd it is of type:\n\nclass( class_start )\n\n[1] \"Date\"\n\n\nIf you want to make a the date from a different format, you need to specify what elements within the string representation using format codes. These codes (and many more) can be found by looking at ?strptime.\n\nclass_end &lt;- as.Date( \"5/10/21\", format = \"%m/%d/%y\")\nclass_end\n\n[1] \"2021-05-10\"\n\n\nI like to use some higher-level date functions from the lubridate library. If you don’t have it installed, do so using the normal approach.\n\nlibrary( lubridate )\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\nDate objects can be put into vectors and sequences just like other objects.\n\nsemester &lt;- seq( class_start, class_end, by = \"1 day\")\nsemester\n\n  [1] \"2021-01-15\" \"2021-01-16\" \"2021-01-17\" \"2021-01-18\" \"2021-01-19\"\n  [6] \"2021-01-20\" \"2021-01-21\" \"2021-01-22\" \"2021-01-23\" \"2021-01-24\"\n [11] \"2021-01-25\" \"2021-01-26\" \"2021-01-27\" \"2021-01-28\" \"2021-01-29\"\n [16] \"2021-01-30\" \"2021-01-31\" \"2021-02-01\" \"2021-02-02\" \"2021-02-03\"\n [21] \"2021-02-04\" \"2021-02-05\" \"2021-02-06\" \"2021-02-07\" \"2021-02-08\"\n [26] \"2021-02-09\" \"2021-02-10\" \"2021-02-11\" \"2021-02-12\" \"2021-02-13\"\n [31] \"2021-02-14\" \"2021-02-15\" \"2021-02-16\" \"2021-02-17\" \"2021-02-18\"\n [36] \"2021-02-19\" \"2021-02-20\" \"2021-02-21\" \"2021-02-22\" \"2021-02-23\"\n [41] \"2021-02-24\" \"2021-02-25\" \"2021-02-26\" \"2021-02-27\" \"2021-02-28\"\n [46] \"2021-03-01\" \"2021-03-02\" \"2021-03-03\" \"2021-03-04\" \"2021-03-05\"\n [51] \"2021-03-06\" \"2021-03-07\" \"2021-03-08\" \"2021-03-09\" \"2021-03-10\"\n [56] \"2021-03-11\" \"2021-03-12\" \"2021-03-13\" \"2021-03-14\" \"2021-03-15\"\n [61] \"2021-03-16\" \"2021-03-17\" \"2021-03-18\" \"2021-03-19\" \"2021-03-20\"\n [66] \"2021-03-21\" \"2021-03-22\" \"2021-03-23\" \"2021-03-24\" \"2021-03-25\"\n [71] \"2021-03-26\" \"2021-03-27\" \"2021-03-28\" \"2021-03-29\" \"2021-03-30\"\n [76] \"2021-03-31\" \"2021-04-01\" \"2021-04-02\" \"2021-04-03\" \"2021-04-04\"\n [81] \"2021-04-05\" \"2021-04-06\" \"2021-04-07\" \"2021-04-08\" \"2021-04-09\"\n [86] \"2021-04-10\" \"2021-04-11\" \"2021-04-12\" \"2021-04-13\" \"2021-04-14\"\n [91] \"2021-04-15\" \"2021-04-16\" \"2021-04-17\" \"2021-04-18\" \"2021-04-19\"\n [96] \"2021-04-20\" \"2021-04-21\" \"2021-04-22\" \"2021-04-23\" \"2021-04-24\"\n[101] \"2021-04-25\" \"2021-04-26\" \"2021-04-27\" \"2021-04-28\" \"2021-04-29\"\n[106] \"2021-04-30\" \"2021-05-01\" \"2021-05-02\" \"2021-05-03\" \"2021-05-04\"\n[111] \"2021-05-05\" \"2021-05-06\" \"2021-05-07\" \"2021-05-08\" \"2021-05-09\"\n[116] \"2021-05-10\"\n\n\nSome helpful functions include the Julian Ordinal Day (e.g., number of days since the start of the year).\n\nordinal_day &lt;- yday( semester[102] )\nordinal_day\n\n[1] 116\n\n\nThe weekday as an integer (0-6 starting on Sunday), which I use to index the named values.\n\ndays_of_week &lt;- c(\"Sunday\",\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\")\nx &lt;- wday( semester[32] )\ndays_of_week[ x ]\n\n[1] \"Monday\"\n\n\nSince we did not specify a time, things like hour() and minute() do not provide any usable information.\n\n\n2.5.2 Dates & Times\nTo add time to the date objects, we need to specify both date and time specifically. Here are some example data:\n\ndf &lt;- data.frame( Date = c(\"8/21/2004 7:33:51 AM\",\n                           \"7/12/2008 9:23:08 PM\",\n                           \"2/14/2010 8:18:30 AM\",\n                           \"12/23/2018 11:11:45 PM\",\n                           \"2/1/2019 4:42:00 PM\",\n                           \"5/17/2012 1:23:23 AM\",\n                           \"12/11/2020 9:48:02 PM\") )\nsummary( df )\n\n     Date          \n Length:7          \n Class :character  \n Mode  :character  \n\n\nJust like above, if we want to turn these into date and time objects we must be able to tell the parsing algorithm what elements are represented in each entry. There are many ways to make dates and time, 10/14 or 14 Oct or October 14 or Julian day 287, etc. These are designated by a format string were we indicate what element represents a day or month or year or hour or minute or second, etc. These are found by looking at the documentation for?strptime.\nIn our case, we have:\n- Month as 1 or 2 digits\n- Day as 1 or 2 digits\n- Year as 4 digits\n- a space to separate date from time\n- hour (not 24-hour though)\n- minutes in 2 digits\n- seconds in 2 digits\n- a space to separate time from timezone\n- timezone\n- / separating date objects\n- : separating time objects\nTo make the format string, we need to look up how to encode these items. The items in df for a date & time object such as 2/1/2019 4:42:00 PM have the format string:\n\nformat &lt;- \"%m/%d/%Y %I:%M:%S %p\"\n\nNow, we can convert the character string in the data frame to a date and time object.\n\n\n2.5.3 Lubridate\nInstead of using the built-in as.Date() functionality, I like the lubridate library1 as it has a lot of additional functionality that we’ll play with a bit later.\n\ndf$Date &lt;- parse_date_time( df$Date, \n                            orders=format, \n                            tz = \"EST\" )\nsummary( df )\n\n      Date                       \n Min.   :2004-08-21 07:33:51.00  \n 1st Qu.:2009-04-29 14:50:49.00  \n Median :2012-05-17 01:23:23.00  \n Mean   :2013-07-11 07:28:39.85  \n 3rd Qu.:2019-01-12 19:56:52.50  \n Max.   :2020-12-11 21:48:02.00  \n\nclass( df$Date )\n\n[1] \"POSIXct\" \"POSIXt\" \n\n\nNow, we can ask Date-like questions about the data such as what day of the week was the first sample taken?\n\nweekdays( df$Date[1] )\n\n[1] \"Saturday\"\n\n\nWhat is the range of dates?\n\nrange( df$Date )\n\n[1] \"2004-08-21 07:33:51 EST\" \"2020-12-11 21:48:02 EST\"\n\n\nWhat is the median of samples\n\nmedian( df$Date )\n\n[1] \"2012-05-17 01:23:23 EST\"\n\n\nand what julian ordinal day (e.g., how many days since start of the year) is the last record.\n\nyday( df$Date[4] )\n\n[1] 357\n\n\nJust for fun, I’ll add a column to the data that has weekday.\n\ndf$Weekday &lt;- weekdays( df$Date )\ndf\n\n                 Date  Weekday\n1 2004-08-21 07:33:51 Saturday\n2 2008-07-12 21:23:08 Saturday\n3 2010-02-14 08:18:30   Sunday\n4 2018-12-23 23:11:45   Sunday\n5 2019-02-01 16:42:00   Friday\n6 2012-05-17 01:23:23 Thursday\n7 2020-12-11 21:48:02   Friday\n\n\nHowever, we should probably turn it into a factor (e.g., a data type with pre-defined levels—and for us here—an intrinsic order of the levels).\n\ndf$Weekday &lt;- factor( df$Weekday, \n                        ordered = TRUE, \n                        levels = days_of_week\n                        )\nsummary( df$Weekday )\n\n   Sunday    Monday   Tuesday Wednesday  Thursday    Friday  Saturday \n        2         0         0         0         1         2         2 \n\n\n\n\n2.5.4 Filtering on Date Objects\nWe can easily filter the content within a data.frame using some helper functions such as hour(), minute(), weekday(), etc. Here are some examples including pulling out the weekends.\n\nweekends &lt;- df[ df$Weekday %in% c(\"Saturday\",\"Sunday\"), ]\nweekends\n\n                 Date  Weekday\n1 2004-08-21 07:33:51 Saturday\n2 2008-07-12 21:23:08 Saturday\n3 2010-02-14 08:18:30   Sunday\n4 2018-12-23 23:11:45   Sunday\n\n\nfinding items that are in the past (paste being defined as the last time this document was knit).\n\npast &lt;- df$Date[ df$Date &lt; Sys.time() ]\npast\n\n[1] \"2004-08-21 07:33:51 EST\" \"2008-07-12 21:23:08 EST\"\n[3] \"2010-02-14 08:18:30 EST\" \"2018-12-23 23:11:45 EST\"\n[5] \"2019-02-01 16:42:00 EST\" \"2012-05-17 01:23:23 EST\"\n[7] \"2020-12-11 21:48:02 EST\"\n\n\nItems that are during working hours\n\nwork &lt;- df$Date[ hour(df$Date) &gt;= 9 & hour(df$Date) &lt;= 17 ]\nwork\n\n[1] \"2019-02-01 16:42:00 EST\"\n\n\nAnd total range of values in days using normal arithmatic operations such as the minus operator.\n\nmax(df$Date) - min(df$Date)\n\nTime difference of 5956.593 days",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Data Types</span>"
    ]
  },
  {
    "objectID": "basic_data_narrative.html#questions",
    "href": "basic_data_narrative.html#questions",
    "title": "2  Basic Data Types",
    "section": "2.6 Questions",
    "text": "2.6 Questions\nIf you have any questions for me specifically on this topic, please feel free to contact me directly or drop a post on the discussion board on Canvas.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Data Types</span>"
    ]
  },
  {
    "objectID": "basic_data_narrative.html#footnotes",
    "href": "basic_data_narrative.html#footnotes",
    "title": "2  Basic Data Types",
    "section": "",
    "text": "If you get an error saying something like, “there is no package named lubridate” then use install.packages(\"lubridate\") and install it. You only need to do this once.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Data Types</span>"
    ]
  },
  {
    "objectID": "containers_narrative.html",
    "href": "containers_narrative.html",
    "title": "3  Basic Data Containers in R",
    "section": "",
    "text": "3.1 Vectors\nVectors are the most basic data container in R. They must contain data of the exact same type and are constructed using the combine() function, which is abbreviated as c() because good programmers are lazy programmers. 1\nHere is an example with some numbers.\nx &lt;- c(1,2,3)\nx\n\n[1] 1 2 3\nVectors can contain any of the base data types.\ny &lt;- c(TRUE, TRUE, FALSE, FALSE)\ny\n\n[1]  TRUE  TRUE FALSE FALSE\nz &lt;- c(\"Bob\",\"Alice\",\"Thomas\")\nz\n\n[1] \"Bob\"    \"Alice\"  \"Thomas\"\nEach vector has an inherent length representing the number of elements it contains.\nlength(x)\n\n[1] 3",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Basic Data Containers in R</span>"
    ]
  },
  {
    "objectID": "containers_narrative.html#vectors",
    "href": "containers_narrative.html#vectors",
    "title": "3  Basic Data Containers in R",
    "section": "",
    "text": "3.1.1 Introspection\nWhen asked, a vector reports the class of itself as the type of data contained within it.\n\nclass(x)\n\n[1] \"numeric\"\n\nclass(y)\n\n[1] \"logical\"\n\nclass(z)\n\n[1] \"character\"\n\n\nhowever, a vector is also a data type. As such, it has the is.vector() function. So this x can be both a vector and a numeric.\n\nis.vector( x ) && is.numeric( x )\n\n[1] TRUE\n\n\n\n\n3.1.2 Sequences\nThere are a lot of times when we require a sequnce of values and it would get a bit tedious to type them all out manually. R has several options for creating vectors that are comprised of a sequence of values.\nThe easiest type is the colon operator, that will generate a seqeunce of numerical values from the number on the left to the number on the right\n\n1:10 -&gt; y\ny\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nIt also works in the other direction (descending).\n\n10:1\n\n [1] 10  9  8  7  6  5  4  3  2  1\n\n\nHowever, it is only available to make a sequences where the increment from one value to the next is 1.\n\n3.2:5.7\n\n[1] 3.2 4.2 5.2\n\n\nFor more fine-grained control, we can use the function seq() to iterate across a range of values and specify either the step size (here from 1-10 by 3’s)\n\nseq(1,10,by=3)\n\n[1]  1  4  7 10\n\n\nOR the length of the response and it will figure out the step size to give you the right number of elements.\n\nseq( 119, 121, length.out = 6)\n\n[1] 119.0 119.4 119.8 120.2 120.6 121.0\n\n\n\n\n3.1.3 Indexing & Access\nTo access and change values within a vector, we used square brackets and the number of the entry of interest. It should be noted that in R, the first element of a vector is # 1.\nSo, to get to the third element of the x vector, we would:\n\nx[3]\n\n[1] 3\n\n\nIf you ask for values in the vector off the end (e.g., the index is beyond the length of the vector) it will return missing data.\n\nx[5]\n\n[1] NA\n\n\nIn addition to getting the values from a vector, assignment of individual values proceeds similarily.\n\nx[2] &lt;- 42\nx\n\n[1]  1 42  3\n\n\nIf you assign a value to a vector that is way off the end, it will fill in the intermediate values wtih NA for you.\n\nx[7] &lt;- 43\nx\n\n[1]  1 42  3 NA NA NA 43\n\n\n\n\n3.1.4 Vector Operations\nJust like individual values for each data type, vectors of these data types can also be operated using the same operators. Consider the two vectors x (a sequence) and y (a random selection from a Poisson distribution), both with 5 elements.\n\nx &lt;- 1:5\ny &lt;- rpois(5,2)\nx\n\n[1] 1 2 3 4 5\n\ny\n\n[1] 1 1 3 3 1\n\n\nMathematics operations are done element-wise. Here is an example using addition.\n\nx + y \n\n[1] 2 3 6 7 6\n\n\nas well as exponents.\n\nx^y\n\n[1]  1  2 27 64  5\n\n\nIf the lengths of the vectors are not the same R will implement a recycling rule where the shorter of the vectors is repeated until you fill up the size of the longer vector. Here is an example with the 5-element x and the a new 10-element z. Notice how the values in x are repeated in the addition operaiton.\n\nz &lt;- 1:10\nx + z\n\n [1]  2  4  6  8 10  7  9 11 13 15\n\n\nIf the two vectors are not multiples of each other in length, it will still recycle the shorter one but will also give you a warning that the two vectors are not conformant (just a FYI).\n\nx + 1:8\n\nWarning in x + 1:8: longer object length is not a multiple of shorter object\nlength\n\n\n[1]  2  4  6  8 10  7  9 11\n\n\nThe operations used are dependent upon the base data type. For example, the following character values can be passed along to the paste() function to put each of the elements in the first vectoer with the corresponding values in the second vector (and specifying the separator).\n\na &lt;- c(\"Bob\",\"Alice\",\"Thomas\")\nb &lt;- c(\"Biologist\",\"Chemist\",\"Mathematician\")\npaste( a, b, sep=\" is a \")\n\n[1] \"Bob is a Biologist\"        \"Alice is a Chemist\"       \n[3] \"Thomas is a Mathematician\"\n\n\nSo, in addition to being able to work on individual values, all functions are also vector functions.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Basic Data Containers in R</span>"
    ]
  },
  {
    "objectID": "containers_narrative.html#matrices",
    "href": "containers_narrative.html#matrices",
    "title": "3  Basic Data Containers in R",
    "section": "3.2 Matrices",
    "text": "3.2 Matrices\nA matrix is a 2-dimensional container for the same kind of data as well. The two dimensions are represented as rows and columns in a rectangular configuration. Here I will make a 3x3 vector consisting of a sequence of numbers from 1 to 9.\n\nX &lt;- matrix( 1:9, nrow=3, ncol=3 )\nX\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\nIt is a bit redundant to have both nrow and ncol with nrow * ncol = length(sequence), you can just specify one of them and it will work out the other dimension.\n\n3.2.1 Indexing\nJust like a vector, matrices use square brackets and the row & column number (in that order) to access indiviudal elements. Also, just like vectors, both rows and columns start at 1 (not zero). So to replace the value in the second row and second column with the number 42, we do this.\n\nX[2,2] &lt;- 42\nX\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2   42    8\n[3,]    3    6    9\n\n\nMatrices are actually structures fundamental to things like linear algebra. As such, there are many operations that can be applied to matrices, both unary and binary.\nA transpose is a translation of a matrix that switches the rows and columns. In R it is done by the function t(). Here I use this to define another matrix.\n\nY &lt;- t(X)\nY\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4   42    6\n[3,]    7    8    9\n\n\nBinary operators using the normal operators in the top row of your keyboard are generally element-wise operations. Here the addition of these two matrices require:\n1. Both matrices have the same number of rows.\n2. Both matrices have the same number of columns.\n3. Both matrices have the same internal data types.\nHere is an example of addition (notic how the resulting [1,1] object is equal to X[1,1] + Y[1,1])\n\nX + Y\n\n     [,1] [,2] [,3]\n[1,]    2    6   10\n[2,]    6   84   14\n[3,]   10   14   18\n\n\nThe same for element-wise multiplication.\n\nX * Y\n\n     [,1] [,2] [,3]\n[1,]    1    8   21\n[2,]    8 1764   48\n[3,]   21   48   81\n\n\nHowever, there is another kind of matrix mutliplication that sums the product or rows and columns. Since this is also a variety of multiplication but is carried out differently, we need to use a different operator. Here the matrix mutliplication operator is denoted as the combination of characters %*%.\n\nX %*% Y\n\n     [,1] [,2] [,3]\n[1,]   66  226   90\n[2,]  226 1832  330\n[3,]   90  330  126\n\n\nThis operation has a few different constraints:\n\nThe number of columns in the left matrix must equal the number of rows in the right one.\nThe resulting matrix will have the number of rows equal to that of the right matrix.\nThe resulting matrix will have the number of columns equal to that of the left matrix.\nThe resulting element at the \\(i\\) \\(j\\) position is the sum of the multipliation of the elements in the \\(i^{th}\\) row of the left matrix and the \\(j^{th}\\) column of the right one.\n\nSo the resulting element in [1,3] position is found by \\(1*3 + 4*6 + 7*9 = 90\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Basic Data Containers in R</span>"
    ]
  },
  {
    "objectID": "containers_narrative.html#lists",
    "href": "containers_narrative.html#lists",
    "title": "3  Basic Data Containers in R",
    "section": "3.3 Lists",
    "text": "3.3 Lists\nLists are a more flexible container type. Here, lists can contain different types of data in a single list. Here is an example of a list made with a few character vluaes, a numeric, a constant, and a logical value.\n\nlst &lt;- list(\"A\",\"B\",323423.3, pi, TRUE)\n\nWhen you print out a list made like this, it will indicate each element as a numeric value in double square brackets.\n\nlst\n\n[[1]]\n[1] \"A\"\n\n[[2]]\n[1] \"B\"\n\n[[3]]\n[1] 323423.3\n\n[[4]]\n[1] 3.141593\n\n[[5]]\n[1] TRUE\n\n\n\n3.3.1 Indexing\nIndexing values in a list can be done using these numbers. To get and reset the values in the second element of the list, one would:\n\nlst[[2]] &lt;- \"C\"\nlst\n\n[[1]]\n[1] \"A\"\n\n[[2]]\n[1] \"C\"\n\n[[3]]\n[1] 323423.3\n\n[[4]]\n[1] 3.141593\n\n[[5]]\n[1] TRUE\n\n\n\n\n3.3.2 Named Lists\nLists can be more valuable if we use names for the keys instead of just numbers. Here, I make an empty list and then assign values to it using names (as character values) in square brakets.\n\nmyInfo &lt;- list()\nmyInfo[\"First Name\"] &lt;- \"Rodney\"\nmyInfo[\"Second Name\"] &lt;- \"Dyer\"\nmyInfo[\"Favorite Number\"] &lt;- 42\n\nWhen showing named lists, it prints included items as:\n\nmyInfo\n\n$`First Name`\n[1] \"Rodney\"\n\n$`Second Name`\n[1] \"Dyer\"\n\n$`Favorite Number`\n[1] 42\n\n\nIn addition to the square bracket approach, we can also use as $ notation to add elements to the list (like shown above).\n\nmyInfo$Vegitarian &lt;- FALSE\n\nBoth are equivallent.\n\nmyInfo\n\n$`First Name`\n[1] \"Rodney\"\n\n$`Second Name`\n[1] \"Dyer\"\n\n$`Favorite Number`\n[1] 42\n\n$Vegitarian\n[1] FALSE\n\n\nIn addition to having different data types, you can also have different sized data types inside a list. Here I add a vector (a valid data type as shown above) to the list.\n\nmyInfo$Homes &lt;- c(\"RVA\",\"Oly\",\"SEA\")\nmyInfo\n\n$`First Name`\n[1] \"Rodney\"\n\n$`Second Name`\n[1] \"Dyer\"\n\n$`Favorite Number`\n[1] 42\n\n$Vegitarian\n[1] FALSE\n\n$Homes\n[1] \"RVA\" \"Oly\" \"SEA\"\n\n\nTo access these values, we can use a combination of $ notation and [] on the resulting vector.\n\nmyInfo$Homes[2]\n\n[1] \"Oly\"\n\n\nWhen elements in a list are defined using named keys, the list itself can be asked for the keys using names().\n\nnames(myInfo)\n\n[1] \"First Name\"      \"Second Name\"     \"Favorite Number\" \"Vegitarian\"     \n[5] \"Homes\"          \n\n\nThis can be helpful at times when you did not create the list yourself and want to see what is inside of them.\n\n\n3.3.3 Spaces in Names\nAs you see above, this list has keys such as “First Name” and “Vegitarian”. The first one has a space inside of it whereas the second one does not. This is a challenge. If we were to try to use the first key as\n\nmyInfo$First Name\n\nWould give you an error (if I ran the chunck but I cannot because it is an error and won’t let me compile this document if I do). For names that have spaces, we need to enclose them inside back-ticks (as shown in the output above).\n\nmyInfo$`First Name`\n\n[1] \"Rodney\"\n\n\nSo feel free to use names that make sense, but if you do, you’ll need to treat them a bit specially using the backticks.\n\n\n3.3.4 Analysis Output\nBy far, the most common location for lists is when you do some kind of analysis. Almost all analyses return the restuls as a special kind of list.\nHere is an example looking at some data from three species of Iris on the lengths and width of sepal and petals. The data look like:\n\n\n\n\n\n\n\n\nFigure 3.1: The distribution of sepal and petal lengths from three species of Iris.\n\n\n\n\n\nWe can look at the correlation between two variable using the built-in cor.test() function.\n\niris.test &lt;- cor.test( iris$Sepal.Length, iris$Petal.Length )\n\nWe can print the output and it will format the results in a proper way.\n\niris.test\n\n\n    Pearson's product-moment correlation\n\ndata:  iris$Sepal.Length and iris$Petal.Length\nt = 21.646, df = 148, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8270363 0.9055080\nsample estimates:\n      cor \n0.8717538 \n\n\nHowever, the elements in the iris.test are simply a list.\n\nnames(iris.test)\n\n[1] \"statistic\"   \"parameter\"   \"p.value\"     \"estimate\"    \"null.value\" \n[6] \"alternative\" \"method\"      \"data.name\"   \"conf.int\"   \n\n\nIf fact, the contents of the output are just keys and values, even though when we printed it all out, it was formatted as a much more informative output.\n\n\n\n\n\n\n\n\n\nValues\n\n\n\n\nstatistic.t\n21.6460193457598\n\n\nparameter.df\n148\n\n\np.value\n1.03866741944978e-47\n\n\nestimate.cor\n0.871753775886583\n\n\nnull.value.correlation\n0\n\n\nalternative\ntwo.sided\n\n\nmethod\nPearson's product-moment correlation\n\n\ndata.name\niris$Sepal.Length and iris$Petal.Length\n\n\nconf.int1\n0.827036329664362\n\n\nconf.int2\n0.905508048821454\n\n\n\n\n\n\n\nWe will come back to this special kind of printing later when discussing functions but for now, lets just consider how cool this is because we can access the raw values of the analysis directly. We an also easily incorporate the findings of analyses, such as this simple correlation test, and insert the content into the text. All you have to do is address the components of the analysis as in-text r citation. Here is an example where I include the values of:\n\niris.test$estimate\n\n      cor \n0.8717538 \n\niris.test$statistic\n\n       t \n21.64602 \n\niris.test$p.value\n\n[1] 1.038667e-47\n\n\nHere is an example paragraph (see the raw quarto document to see the formatting).\n\nThere was a significant relationship between sepal and petal length (Pearson Correlation, \\(\\rho =\\) 0.872, \\(t =\\) 21.6, P = 1.04e-47).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Basic Data Containers in R</span>"
    ]
  },
  {
    "objectID": "containers_narrative.html#data-frames",
    "href": "containers_narrative.html#data-frames",
    "title": "3  Basic Data Containers in R",
    "section": "3.4 Data Frames",
    "text": "3.4 Data Frames\nThe data.frame is the most common container for all the data you’ll be working with in R. It is kind of like a spreadsheet in that each column of data is the same kind of data measured on all objects (e.g., weight, survival, population, etc.) and each row represents one observation that has a bunch of different kinds of measurements associated with it.\nHere is an example with three different data types (the z is a random sample of TRUE/FALSE equal in length to the other elements).\n\nx &lt;- 1:10\ny &lt;- LETTERS[11:20]\nz &lt;- sample( c(TRUE,FALSE), size=10, replace=TRUE )\n\nI can put them into a data.frame object as:\n\ndf &lt;- data.frame( TheNums = x,\n                  TheLetters = y,\n                  TF = z\n                  )\ndf\n\n   TheNums TheLetters    TF\n1        1          K  TRUE\n2        2          L FALSE\n3        3          M  TRUE\n4        4          N  TRUE\n5        5          O  TRUE\n6        6          P  TRUE\n7        7          Q  TRUE\n8        8          R FALSE\n9        9          S FALSE\n10      10          T  TRUE\n\n\nSince each column is its own ‘type’ we can easily get a summary of the elements within it using summary().\n\nsummary( df )\n\n    TheNums       TheLetters            TF         \n Min.   : 1.00   Length:10          Mode :logical  \n 1st Qu.: 3.25   Class :character   FALSE:3        \n Median : 5.50   Mode  :character   TRUE :7        \n Mean   : 5.50                                     \n 3rd Qu.: 7.75                                     \n Max.   :10.00                                     \n\n\nAnd depending upon the data type, the output may give numerical, counts, or just description of the contents.\n\n3.4.1 Indexing\nJust like a list, a data.frame can be defined as having named columns. The distinction here is that each column should have the same number of elements in it, whereas a list may have differnet lengths to the elements.\n\nnames( df )\n\n[1] \"TheNums\"    \"TheLetters\" \"TF\"        \n\n\nAnd like the list, we can easily use the $ operator to access the vectors components.\n\ndf$TheLetters\n\n [1] \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\" \"T\"\n\nclass( df$TheLetters )\n\n[1] \"character\"\n\n\nIndexing and grabbing elements can be done by either the column name (with $) and a square bracket OR by the [row,col] indexing like the matrix above.\n\ndf$TheLetters[3]\n\n[1] \"M\"\n\ndf[3,2]\n\n[1] \"M\"\n\n\nJust like a matrix, the dimensions of the data.frame is defined by the number of rows and columns.\n\ndim( df )\n\n[1] 10  3\n\nnrow( df )\n\n[1] 10\n\nncol( df )\n\n[1] 3\n\n\n\n\n3.4.2 Loading Data\nBy far, you will most often NOT be making data by hand but instead will be loading it from external locations. here is an example of how we can load in a CSV file that is located in the GitHub repository for this topic. As this is a public repository, we can get a direct URL to the file. For simplicity, I’ll load in tidyverse and use some helper functions contained therein.\n\nlibrary( tidyverse )\n\nThe URL for this repository is\n\nurl &lt;- \"https://raw.githubusercontent.com/DyerlabTeaching/Data-Containers/main/data/arapat.csv\"\n\nAnd we can read it in directly (as long as we have an internet connection) as:\n\nbeetles &lt;- read_csv( url )\n\nRows: 39 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Stratum\ndbl (2): Longitude, Latitude\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNotice how the funtion tells us a few things about the data.\nThe data itself consists of:\n\nsummary( beetles )\n\n   Stratum            Longitude         Latitude    \n Length:39          Min.   :-114.3   Min.   :23.08  \n Class :character   1st Qu.:-112.9   1st Qu.:24.52  \n Mode  :character   Median :-111.5   Median :26.21  \n                    Mean   :-111.7   Mean   :26.14  \n                    3rd Qu.:-110.4   3rd Qu.:27.47  \n                    Max.   :-109.1   Max.   :29.33  \n\n\nwhich looks like:\n\nbeetles\n\n# A tibble: 39 × 3\n   Stratum Longitude Latitude\n   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;\n 1 88          -114.     29.3\n 2 9           -114.     29.0\n 3 84          -114.     29.0\n 4 175         -113.     28.7\n 5 177         -114.     28.7\n 6 173         -113.     28.4\n 7 171         -113.     28.2\n 8 89          -113.     28.0\n 9 159         -113.     27.5\n10 SFr         -113.     27.4\n# ℹ 29 more rows\n\n\nWe can quickly use these data and make an interactive labeled map of it in a few lines of code (click on a marker).\n\nlibrary( leaflet )\nbeetles %&gt;%\n  leaflet() %&gt;%\n  addProviderTiles(provider = providers$Esri.WorldTopo) %&gt;%\n  addMarkers( ~Longitude, ~Latitude,popup = ~Stratum )",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Basic Data Containers in R</span>"
    ]
  },
  {
    "objectID": "containers_narrative.html#questions",
    "href": "containers_narrative.html#questions",
    "title": "3  Basic Data Containers in R",
    "section": "3.5 Questions",
    "text": "3.5 Questions\nIf you have any questions for me specifically on this topic, please post as an Issue in your repository, otherwise consider posting to the discussion board on Canvas.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Basic Data Containers in R</span>"
    ]
  },
  {
    "objectID": "containers_narrative.html#footnotes",
    "href": "containers_narrative.html#footnotes",
    "title": "3  Basic Data Containers in R",
    "section": "",
    "text": "The more lines of code that you write, the more likely there will be either a grammatical error (easier to find) or a logical one (harder to find).↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Basic Data Containers in R</span>"
    ]
  },
  {
    "objectID": "tidyverse_narrative.html",
    "href": "tidyverse_narrative.html",
    "title": "4  Tidyverse",
    "section": "",
    "text": "4.1 The Tidyverse Approach\nThis is the first introduction to tidyverse and is the key skill necessary to become proficient at data analysis.\nlibrary( tidyverse )\nlibrary( lubridate )",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse_narrative.html#the-tidyverse-approach",
    "href": "tidyverse_narrative.html#the-tidyverse-approach",
    "title": "4  Tidyverse",
    "section": "",
    "text": "4.1.1 The Data\nFor this topic we will use some example data from the Rice Rivers Center. These data represent both atmospheric and water data collected from instrumentation on-site. I have stored these data in a spreadsheet that is shared on Google Drive as a CSV file.\nYou can look at it here.\n\n\n4.1.2 The Data in R\nSo let’s load it into memory and take a look at it.\n\nurl &lt;- \"https://docs.google.com/spreadsheets/d/1Mk1YGH9LqjF7drJE-td1G_JkdADOU0eMlrP01WFBT8s/pub?gid=0&single=true&output=csv\"\nrice &lt;- read_csv( url )\n\nRows: 8199 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): DateTime\ndbl (22): RecordID, PAR, WindSpeed_mph, WindDir, AirTempF, RelHumidity, BP_H...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsummary( rice )\n\n   DateTime            RecordID          PAR           WindSpeed_mph   \n Length:8199        Min.   :43816   Min.   :   0.000   Min.   : 0.000  \n Class :character   1st Qu.:45866   1st Qu.:   0.000   1st Qu.: 2.467  \n Mode  :character   Median :47915   Median :   0.046   Median : 4.090  \n                    Mean   :47915   Mean   : 241.984   Mean   : 5.446  \n                    3rd Qu.:49964   3rd Qu.: 337.900   3rd Qu.: 7.292  \n                    Max.   :52014   Max.   :1957.000   Max.   :30.650  \n                                                                       \n    WindDir          AirTempF       RelHumidity        BP_HG      \n Min.   :  0.00   Min.   : 3.749   Min.   :15.37   Min.   :29.11  \n 1st Qu.: 37.31   1st Qu.:31.545   1st Qu.:42.25   1st Qu.:29.87  \n Median :137.30   Median :37.440   Median :56.40   Median :30.01  \n Mean   :146.20   Mean   :38.795   Mean   :58.37   Mean   :30.02  \n 3rd Qu.:249.95   3rd Qu.:46.410   3rd Qu.:76.59   3rd Qu.:30.21  \n Max.   :360.00   Max.   :74.870   Max.   :93.00   Max.   :30.58  \n                                                                  \n    Rain_in            H2O_TempC       SpCond_mScm      Salinity_ppt   \n Min.   :0.0000000   Min.   :-0.140   Min.   :0.0110   Min.   :0.0000  \n 1st Qu.:0.0000000   1st Qu.: 3.930   1st Qu.:0.1430   1st Qu.:0.0700  \n Median :0.0000000   Median : 5.450   Median :0.1650   Median :0.0800  \n Mean   :0.0008412   Mean   : 5.529   Mean   :0.1611   Mean   :0.0759  \n 3rd Qu.:0.0000000   3rd Qu.: 7.410   3rd Qu.:0.1760   3rd Qu.:0.0800  \n Max.   :0.3470000   Max.   :13.300   Max.   :0.2110   Max.   :0.1000  \n                     NA's   :1        NA's   :1        NA's   :1       \n       PH           PH_mv        Turbidity_ntu       Chla_ugl    \n Min.   :6.43   Min.   :-113.8   Min.   :  6.20   Min.   :  1.3  \n 1st Qu.:7.50   1st Qu.: -47.8   1st Qu.: 15.50   1st Qu.:  3.7  \n Median :7.58   Median : -43.8   Median : 21.80   Median :  6.7  \n Mean   :7.60   Mean   : -44.5   Mean   : 24.54   Mean   :137.3  \n 3rd Qu.:7.69   3rd Qu.: -38.9   3rd Qu.: 30.30   3rd Qu.:302.6  \n Max.   :9.00   Max.   :  28.5   Max.   :187.70   Max.   :330.1  \n NA's   :1      NA's   :1        NA's   :1        NA's   :1      \n   BGAPC_CML        BGAPC_rfu         ODO_sat         ODO_mgl     \n Min.   :   188   Min.   :  0.10   Min.   : 87.5   Min.   :10.34  \n 1st Qu.:   971   1st Qu.:  0.50   1st Qu.: 99.2   1st Qu.:12.34  \n Median :  1369   Median :  0.70   Median :101.8   Median :12.88  \n Mean   :153571   Mean   : 72.91   Mean   :102.0   Mean   :12.88  \n 3rd Qu.:345211   3rd Qu.:163.60   3rd Qu.:104.1   3rd Qu.:13.34  \n Max.   :345471   Max.   :163.70   Max.   :120.8   Max.   :14.99  \n NA's   :1        NA's   :1        NA's   :1       NA's   :1      \n    Depth_ft        Depth_m      SurfaceWaterElev_m_levelNad83m\n Min.   :12.15   Min.   :3.705   Min.   :-32.53                \n 1st Qu.:14.60   1st Qu.:4.451   1st Qu.:-31.78                \n Median :15.37   Median :4.684   Median :-31.55                \n Mean   :15.34   Mean   :4.677   Mean   :-31.55                \n 3rd Qu.:16.12   3rd Qu.:4.913   3rd Qu.:-31.32                \n Max.   :17.89   Max.   :5.454   Max.   :-30.78                \n                                                               \n\n\nThese data represent measurements taken every 15 minutes, 24 hours a day, 7 days a week, 365 days a year. For brevity, this file contains measurements starting at 1/1/2014 12:00:00 AM and ending at 3/27/2014 9:30:00 AM (only 8199 records here…).\nIf you look at the summary of the data above, you will see several things, including:\n\nDate and time objects are character\nSome measurements are in Standard and some in Imperial with units in the same file include both °F and °C, as well as measurements in meters, feet, and inches. In fact, there are duplication of data columns in different units (guess what kind of correlation they might have…)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse_narrative.html#verbs-of-analysis",
    "href": "tidyverse_narrative.html#verbs-of-analysis",
    "title": "4  Tidyverse",
    "section": "4.2 Verbs of Analysis",
    "text": "4.2 Verbs of Analysis\nWhen we perform any type of data manipulation, we use specific verbs. There is a limited lexicon for us to use, but the key here is how we perform these actions, and in which order they are deployed for a huge diversity in outcomes. For now, these basic verbs include:\n\nSelect: Used to grab or reorder columns of data.\nFilter: Used to grab subsets of records (rows) based upon some criteria.\nMutate: Create new columns of data based upon manipulations of existing columns.\nArrange: Order the records (rows) based upon some criteria.\nGroup: Gather records together to perform operations on chunks of them similar to by().\nSummarize: Extract summaries of data (or grouped data) based upon some defined criteria.\n\nIn the following examples, we’ll be using the rice data above. For each verb, I’m going to use the pipe operator (%&gt;%) to send the data into the example functions and then assign the result to a dummy data.frame named df. The arguments passed to each of the verbs are where the magic happens.\n\n4.2.1 The Output\nThe key to these activities is that every one of these functions takes a data.frame as input, does its operations on it, then return a data.frame object as output. The data.frame is the core data container for all of these actions.\n\n\n4.2.2 Select Operator\nThe select() function allows you to choose which columns of data to work with.\n\nrice %&gt;%\n  select( DateTime, AirTempF ) -&gt; df \nhead(df)\n\n# A tibble: 6 × 2\n  DateTime             AirTempF\n  &lt;chr&gt;                   &lt;dbl&gt;\n1 1/1/2014 12:00:00 AM     31.0\n2 1/1/2014 12:15:00 AM     30.7\n3 1/1/2014 12:30:00 AM     31.2\n4 1/1/2014 12:45:00 AM     30.5\n5 1/1/2014 1:00:00 AM      30.9\n6 1/1/2014 1:15:00 AM      30.6\n\n\nSelect can also be used to reorder the columns in a data.frame object. Here are the names of the data columns as initially loaded.\n\nnames( rice )\n\n [1] \"DateTime\"                       \"RecordID\"                      \n [3] \"PAR\"                            \"WindSpeed_mph\"                 \n [5] \"WindDir\"                        \"AirTempF\"                      \n [7] \"RelHumidity\"                    \"BP_HG\"                         \n [9] \"Rain_in\"                        \"H2O_TempC\"                     \n[11] \"SpCond_mScm\"                    \"Salinity_ppt\"                  \n[13] \"PH\"                             \"PH_mv\"                         \n[15] \"Turbidity_ntu\"                  \"Chla_ugl\"                      \n[17] \"BGAPC_CML\"                      \"BGAPC_rfu\"                     \n[19] \"ODO_sat\"                        \"ODO_mgl\"                       \n[21] \"Depth_ft\"                       \"Depth_m\"                       \n[23] \"SurfaceWaterElev_m_levelNad83m\"\n\n\nLet’s say that you wanted to reorder the columns as RecordID, ODO_mgl and PH as the first three columns and leave everything else as is. There is this cool function everthying() that helps out.\n\nrice %&gt;%\n  select( RecordID, ODO_mgl, PH, everything() ) -&gt; df\nnames( df )\n\n [1] \"RecordID\"                       \"ODO_mgl\"                       \n [3] \"PH\"                             \"DateTime\"                      \n [5] \"PAR\"                            \"WindSpeed_mph\"                 \n [7] \"WindDir\"                        \"AirTempF\"                      \n [9] \"RelHumidity\"                    \"BP_HG\"                         \n[11] \"Rain_in\"                        \"H2O_TempC\"                     \n[13] \"SpCond_mScm\"                    \"Salinity_ppt\"                  \n[15] \"PH_mv\"                          \"Turbidity_ntu\"                 \n[17] \"Chla_ugl\"                       \"BGAPC_CML\"                     \n[19] \"BGAPC_rfu\"                      \"ODO_sat\"                       \n[21] \"Depth_ft\"                       \"Depth_m\"                       \n[23] \"SurfaceWaterElev_m_levelNad83m\"\n\n\n\n\n4.2.3 Filter\nThe function filter() works to select records (rows) based upon some criteria. So for example, if I am interested in just records when the airtemp was freezing (and the raw data are in °F). The range of values in the original data was:\n\nrange( rice$AirTempF )\n\n[1]  3.749 74.870\n\n\nbut after filtering using the name of the variable and a logical operator.\n\nrice %&gt;%\n  filter( AirTempF &lt; 32 ) -&gt; df\nrange( df$AirTempF )\n\n[1]  3.749 31.990\n\n\nJust like select(), it is possible to have several conditions, that are compounded (using a logical AND operator) by adding them to the filter() function. Here I also split the conditionals requiring the data to be above freezing air temperatures, not missing data from the PH meter, and water turbidity &lt; 15 ntu’s. I also put each of these onto their own lines and auto-indent does a great job of making it reasonably readable.\n\nrice %&gt;%\n  filter( AirTempF &gt; 32, \n          !is.na(PH), \n          Turbidity_ntu &lt; 15) -&gt; df\nnrow(df)\n\n[1] 1449\n\n\n\n\n4.2.4 Mutate\nThe mutate() function changes values in the table and is quite versatile. Here I will jump back to our old friend mdy_hms() from lubridate and convert the DateTime column, which is\n\nclass( rice$DateTime )\n\n[1] \"character\"\n\n\nand convert it into a real date and time object\n\nrice %&gt;%\n  mutate( Date = mdy_hms(DateTime, tz = \"EST\") ) -&gt; df\nclass( df$Date )\n\n[1] \"POSIXct\" \"POSIXt\" \n\nsummary( df$Date )\n\n                 Min.               1st Qu.                Median \n\"2014-01-01 00:00:00\" \"2014-01-22 08:22:30\" \"2014-02-12 16:45:00\" \n                 Mean               3rd Qu.                  Max. \n\"2014-02-12 16:45:00\" \"2014-03-06 01:07:30\" \"2014-03-27 09:30:00\" \n\n\nYou can also create several mutations in one mutation step.\n\nrice %&gt;%\n  mutate( Date = mdy_hms(DateTime, tz = \"EST\"), \n          Month = month(Date, label = TRUE) ) -&gt; df\nsummary( df$Month )\n\n Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec \n2976 2688 2535    0    0    0    0    0    0    0    0    0 \n\n\n\n\n4.2.5 Arrange\nWe can sort entire data.frame objects based upon the values in one or more of the columns using the arrange() function.\n\nrice %&gt;%\n  arrange( WindSpeed_mph ) -&gt; df \ndf$WindSpeed_mph[1]\n\n[1] 0\n\n\nBy default, it is in ascending order, to reverse it, use the negative operator on the column name object in the function.\n\nrice %&gt;%\n  arrange( -WindSpeed_mph ) -&gt; df \ndf$WindSpeed_mph[1]\n\n[1] 30.65\n\n\nAs above, it is possible to combine many columns of data as criteria for sorting by adding more arguments to the function call.\n\nrice %&gt;%\n  arrange( -WindSpeed_mph, WindDir ) -&gt; df\n\n\n\n4.2.6 Summarise\nThis function is the first one that does not return some version of the original data that was passed to it. Rather, this performs operations on the data and makes a brand new data.frame object.\nEach argument you give to the function performs one or more operations on the data and returns a brand new data.frame object with only the the values specified.\nHere is an example where I am taking the mean air and water temperature (n.b., one is in °F and the other is in °C). Notice the result is a new data.frame object with one row and two new columns defined by how I asked for the summary in the first place. I used single tick notation so I can have a space in the column names.\n\nrice %&gt;%\n  summarize( `Air Temp` = mean( AirTempF), \n             `Water Temp` = mean(H2O_TempC, na.rm=TRUE))\n\n# A tibble: 1 × 2\n  `Air Temp` `Water Temp`\n       &lt;dbl&gt;        &lt;dbl&gt;\n1       38.8         5.53\n\n\n\n\n4.2.7 Group & Summarize\nTo get more than one row in the resulting data.frame from summary(), we need to group the data in some way. The function group_by() does this and is used prior to summary(). Let’s take a look at how we can get the average air and water temp by month. To do this, I’m going to have to do several steps. I’m just going to chain them together using the %&gt;% operator.\n\nrice %&gt;%\n  mutate( Date = mdy_hms( DateTime, \n                          tz=\"EST\"),\n          Month = month( Date, \n                         abbr = FALSE, \n                         label=TRUE) ) %&gt;%\n  group_by( Month ) %&gt;%\n  summarize( `Air Temp` = mean( AirTempF), \n             `Water Temp` = mean( H2O_TempC, \n                                  na.rm=TRUE) )\n\n# A tibble: 3 × 3\n  Month    `Air Temp` `Water Temp`\n  &lt;ord&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n1 January        34.7         3.68\n2 February       39.7         5.29\n3 March          42.6         7.96\n\n\nAs you read the code, notice how easy it is to understand what is going on because of both the pipes and because of the way I am formatting the code itself.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse_narrative.html#flows",
    "href": "tidyverse_narrative.html#flows",
    "title": "4  Tidyverse",
    "section": "4.3 Flows",
    "text": "4.3 Flows\nThis last part really showed off the process of multi-step data manipulations using the pipe operator and the several verbs we introduced. These are both efficient in terms of typing as well as efficient in the way of producing research that makes sense to look at.\nHere are some strategies that I use when building up these manipulation workflows.\n\nDo not think that you have to do the whole thing at once. I typically build up the workflow, one line at a time. Make sure the output from the previous line is what you think it should be then add the next one.\nKeep your code open and airy, it makes it easier to read and to catch any logical errors that may arrise.\nYou can pipe into a lot of different functions. In fact, any function that takes a data frame can be the recipient of a pipe. While developing a workflow, I will often pipe into things like head(), summary(), or View() to take a look at what is coming out of my workflow to make sure it resembles what I think it should look like.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "tidyverse_narrative.html#questions",
    "href": "tidyverse_narrative.html#questions",
    "title": "4  Tidyverse",
    "section": "4.4 Questions",
    "text": "4.4 Questions\nIf you have any questions for me specifically on this topic, please post as an Issue in your repository, otherwise consider posting to the discussion board on Canvas.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidyverse</span>"
    ]
  },
  {
    "objectID": "functions_narrative.html",
    "href": "functions_narrative.html",
    "title": "5  Functions in R",
    "section": "",
    "text": "5.1 A Basic Function\nA function is just a chunck of code, which is wrapped up in a block and given a variable name.\nfoo &lt;- function() { \n  cat(\"bar\")\n}\n\nfoo()\n\nbar\nThe amount of code within a function can be simple like the one above or quite complex. The boundaries of the code are defined by the curly brackets.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functions in R</span>"
    ]
  },
  {
    "objectID": "functions_narrative.html#variable-scope",
    "href": "functions_narrative.html#variable-scope",
    "title": "5  Functions in R",
    "section": "5.2 Variable Scope",
    "text": "5.2 Variable Scope\nWhen we make a function, there is a notion of a scope for variables, which defines where variables are visible from. By default, when you start R you are given a Global Environment Scope that has all the variables and functions you’ve defined thus far. The image below is the one for this document at this stage of development.\n\n\n\nFigure 1: Main Environment in RStudio\n\n\nWhen we work with functions, we encapsulate code within curly-brackets. This protects their scope. Her is an example. In this function, we:\n\nPrint out the value of a variable x\n\nAssign values to the variables x and z\nPrint out the value of the variables x and z.\n\n\nfoo &lt;- function( ) {\n  x &lt;- 12\n  z &lt;- \"bob\"\n  cat(\"x =\", x, \"& z =\", z ,\"inside function.\\n\")\n}\n\nOK, so now let’s call this function.\n\nfoo()\n\nx = 12 & z = bob inside function.\n\n\n\nx &lt;- 42\ncat(\"x =\", x, \"before function.\\n\")\n\nx = 42 before function.\n\nfoo()\n\nx = 12 & z = bob inside function.\n\ncat(\"x =\", x, \"after running function.\\n\")\n\nx = 42 after running function.\n\n\nNOTE: The value of x was changed within the function but those changes were not reflected OUTSIDE of that function. The scope of the variable x inside foo() is local to that function and anything that follows its declaration within the curly brackets of the function. However, it is invisible outside the scope of that function. This is a ‘good thing©’ because if we had visibility of all the variables in all the functions then we would either a) quickly run out of variable names to keep them unique, or b) clobber all of our existing variables by writing over them and changing their values.\nAlso, notice that the variable z that is assigned bob in the function is also not visible in the global environment. What happens in the function, stays in the function.\n\nls()\n\n[1] \"foo\" \"x\"",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functions in R</span>"
    ]
  },
  {
    "objectID": "functions_narrative.html#passing-variables.",
    "href": "functions_narrative.html#passing-variables.",
    "title": "5  Functions in R",
    "section": "5.3 Passing Variables.",
    "text": "5.3 Passing Variables.\nWhile some functions do not take any input, most require some kind of data to work with or values to start using. These variables can are passed into the function code by including them within the function parentheses.\nAny required variables are added within the function definition parentheses. These translate into the names of the variables used within the chunk.\nHere is an example with one required variable, x.\n\nfoo &lt;- function( x ) {\n  print(x)\n}\n\nAnd it can be called by either naming the variable explicity or not.\n\nfoo( x = 23 )\n\n[1] 23\n\nfoo( 42 )\n\n[1] 42\n\n\nHowever, if you require a variable to be passed and it is not given, it will result in an error.\n\nfoo()\n\nError in foo(): argument \"x\" is missing, with no default\n\n\nYou can get around this by making a default value for the variable, which is specified in the function definition as follows:\n\nfoo &lt;- function( x = \"Dr Dyer is my favorite professor\" ) {\n  print(x)\n}\n\nThen if the individual does not fill in\n\nfoo()\n\n[1] \"Dr Dyer is my favorite professor\"",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functions in R</span>"
    ]
  },
  {
    "objectID": "functions_narrative.html#retrieving-results-from-functions",
    "href": "functions_narrative.html#retrieving-results-from-functions",
    "title": "5  Functions in R",
    "section": "5.4 Retrieving Results from Functions",
    "text": "5.4 Retrieving Results from Functions\nSimilarly, many functions we write will return something to the user who is calling it. By default, a function that just does something like print some message or make some plot will return NULL\n\nfoo &lt;- function( name = \"Alice\") {\n  cat(name, \"is in the house.\")\n}\nfoo()\n\nAlice is in the house.\n\n\nBut if I try to assign a variable the results of the function, I get NULL as the value returned.\n\nx &lt;- foo()\n\nAlice is in the house.\n\nclass(x)\n\n[1] \"NULL\"\n\nx\n\nNULL\n\n\nIf you want to return something to the user, you need to be explicit and use the return() function to pass back the variable.\n\nfoo &lt;- function( name = \"Alice\") {\n  response &lt;- paste( name, \"is in the house.\")\n  return( response )\n}\n\n\nwho_is_in_the_house &lt;- foo()\nwho_is_in_the_house\n\n[1] \"Alice is in the house.\"\n\n\nYou can only return one item but it can be a list a data.frame or any other R object.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functions in R</span>"
    ]
  },
  {
    "objectID": "classic_graphics_narrative.html",
    "href": "classic_graphics_narrative.html",
    "title": "6  Narrative Title",
    "section": "",
    "text": "6.1 The Data\nThe iris flower data set (also known as Fisher’s Iris data set) is a multivariate data set introduced by the British statistician, eugenicist, and biologist Ronald Fisher in his 1936 paper entitled, The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis.\nThese data are part of the base R distribution and contain sepal and pedal measurements for three species if congeneric plants, Iris setosa, I. versicolor, and I. virginica.\nHere is what the data summary looks like.\nsummary(iris)\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Narrative Title</span>"
    ]
  },
  {
    "objectID": "classic_graphics_narrative.html#the-data",
    "href": "classic_graphics_narrative.html#the-data",
    "title": "6  Narrative Title",
    "section": "",
    "text": "The three species of iris in the default data set.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Narrative Title</span>"
    ]
  },
  {
    "objectID": "classic_graphics_narrative.html#basic-plotting-in-r",
    "href": "classic_graphics_narrative.html#basic-plotting-in-r",
    "title": "6  Narrative Title",
    "section": "6.2 Basic Plotting in R",
    "text": "6.2 Basic Plotting in R\nThe base R comes with several built-in plotting functions, each of which is accessed through a single function with a wide array of optional arguments that modify the overall appearance.\nHistograms - The Density of A Single Data Vector\n\nhist( iris$Sepal.Length)\n\n\n\n\n\n\n\n\nYou can see that the default values for the hist() function label the x-axis & title on the graph have the names of the variable passed to it, with a y-axis is set to “Frequency”.\n\nxlab & ylab: The names attached to both x- and y-axes.\nmain: The title on top of the graph.\nbreaks: This controls the way in which the original data are partitioned (e.g., the width of the bars along the x-axis).\n\nIf you pass a single number, n to this option, the data will be partitioned into n bins.\nIf you pass a sequence of values to this, it will use this sequence as the boundaries of bins.\n\ncol: The color of the bar (not the border)\nprobability: A flag as either TRUE or FALSE (the default) to have the y-axis scaled by total likelihood of each bins rather than a count of the numbrer of elements in that range.\n\nDensity - Estimating the continuous density of data\n\nd_sepal.length &lt;- density( iris$Sepal.Length )\nd_sepal.length\n\n\nCall:\n    density.default(x = iris$Sepal.Length)\n\nData: iris$Sepal.Length (150 obs.); Bandwidth 'bw' = 0.2736\n\n       x               y            \n Min.   :3.479   Min.   :0.0001495  \n 1st Qu.:4.790   1st Qu.:0.0341599  \n Median :6.100   Median :0.1534105  \n Mean   :6.100   Mean   :0.1905934  \n 3rd Qu.:7.410   3rd Qu.:0.3792237  \n Max.   :8.721   Max.   :0.3968365  \n\n\nThe density() function estimates a continuous probability density function for the data and returns an object that has both x and y values. In fact, it is a special kind of object.\n\nclass(d_sepal.length)\n\n[1] \"density\"\n\n\nBecause of this, the general plot() function knows how to plot these kinds of things.\n\nplot( d_sepal.length )\n\n\n\n\n\n\n\n\nNow, the general plot() function has A TON of options and is overloaded to be able to plot all kinds of data. In addition to xlab and ylab, we modify the following:\n\ncol: Color of the line.\nlwd: Line width\nbty: This covers the ‘box type’, which is the square box around the plot area. I typically use bty=\"n\" because I hate those square boxes around my plots (compare the following 2 plots to see the differences). But you do you.\nxlim & ylim: These dictate the range on both the x- and y-axes. It takes a pair of values such as c(min,max) and then limits (or extends) that axis to to fill that range.\n\nScatter Plots - Plotting two variables\n\nplot( iris$Sepal.Length, iris$Sepal.Width  )\n\n\n\n\n\n\n\n\nHere is the most general plot(). The form of the arguments to this function are x-data and then y-data. The visual representation of the data is determined by the optional values you pass (or if you do not pass any optional values, the default is the scatter plot shown above)\n\n\n\n\n\n\n\nParameter\nDescription\n\n\n\n\ntype\nThe kind of plot to show (’p’oint, ’l’ine, ’b’oth, or ’o’ver). A point plot is the default.\n\n\npch\nThe character (or symbol) being used to plot. There 26 recognized general characters to use for plotting. The default is pch=1.\n\n\ncol\nThe color of the symbols/lines that are plot.\n\n\ncex\nThe magnification size of the character being plot. The default is cex=1 and deviation from that will increase (\\(cex &gt; 1\\)) or decrease (\\(0 &lt; cex &lt; 1\\)) the scaling of the symbols.\n\n\nlwd\nThe width of any lines in the plot.\n\n\nlty\nThe type of line to be plot (solid, dashed, etc.)\n\n\n\n\n\n\n\n\n\n\n\n\nOne of the relevant things you can use the parameter pch for is to differentiate between groups of observations (such as different species for example). Instead of giving it one value, pass it a vector of values whose length is equal to that for x- and y-axis data.\nHere is an example where I coerce the iris$Species data vector into numeric types and use that for symbols.\n\nsymbol &lt;- as.numeric(iris$Species)\nsymbol\n\n  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3\n[112] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n[149] 3 3\n\n\n\nplot( iris$Sepal.Length, iris$Sepal.Width, pch=symbol )\n\n\n\n\n\n\n\n\nWe can use the same technique to use col instead of pch. Here I make a vector of color names and then use the previously defined in the variable symbol.\n\nraw_colors &lt;- c(\"red\",\"gold\",\"forestgreen\")\ncolors &lt;- raw_colors[ symbol ]\ncolors[1:10]\n\n [1] \"red\" \"red\" \"red\" \"red\" \"red\" \"red\" \"red\" \"red\" \"red\" \"red\"\n\n\nIn addition to the general form for the function plot(x,y) we used above, we can use an alternative designation based upon what is called the functional form. The functional form is how we designate functions in R, such as regression anlaysis. This basic syntax for this is y ~ x, that is the response variable (on the y-axis) is a function of the predictor (on the x-axis).\nFor simplicty, I’ll make x and y varibles pointing to the same same data as in the previous graph.\n\ny &lt;- iris$Sepal.Width\nx &lt;- iris$Sepal.Length\n\nThen, the plot() function can be written as (including all the fancy additional stuff we just described):\n\nplot( y ~ x , \n      col=colors, \n      pch=20, \n      bty=\"n\", \n      xlab=\"Sepal Length\", ylab=\"Sepal Width\")\n\n\n\n\n\n\n\n\nThis is much easier to read (also notice how I used serveral lines to put in all the options to the plot function for legibility).\nBar Plots - Quantifying Counts\nThe barplot function takes a set of heights, one for each bar. Let’s quickly grab the mean length for sepals across all three species. There are many ways to do this, here are two, the first being more pedantic and the second more concise.\nThe iris data is in a data.frame that has a column designating the species. We can see which ones using unique().\n\nunique( iris$Species )\n\n[1] setosa     versicolor virginica \nLevels: setosa versicolor virginica\n\n\nTo estimate the mean for each species, we can take values in iris$Sepal.Length for each level of iris$Species using indices.\n\nmu.Setosa &lt;- mean( iris$Sepal.Length[ iris$Species == \"setosa\" ])\nmu.Versicolor &lt;- mean( iris$Sepal.Length[ iris$Species == \"versicolor\" ])\nmu.Virginica &lt;- mean( iris$Sepal.Length[ iris$Species == \"virginica\" ])\n\nmeanSepalLength &lt;- c( mu.Setosa, mu.Versicolor, mu.Virginica )\nmeanSepalLength\n\n[1] 5.006 5.936 6.588\n\n\nWhen we plot these data using barplot() we pass the values and set the names of the bars us\n\nbarplot( meanSepalLength, \n         names.arg = c(\"setosa\",\"versicolor\",\"virginica\"), \n         xlab=\"Iris Species\",\n         ylab=\"Mean Sepal Length\")\n\n\n\n\n\n\n\n\nThe second way to do this is to use the by() function (see ?by for the complete help file). The by function takes the following objects:\n\nThe raw data to use as measurements. Here we will use iris$Sepal.Length as the raw data.\nData designating groups to partition the raw data into (we will use iris$Species).\nThe function that you want to use on each group. (here we will ask for the mean).\n\n\nmeanSepalLength &lt;- by( iris$Sepal.Length, iris$Species, mean )\nmeanSepalLength\n\niris$Species: setosa\n[1] 5.006\n------------------------------------------------------------ \niris$Species: versicolor\n[1] 5.936\n------------------------------------------------------------ \niris$Species: virginica\n[1] 6.588\n\n\nThe data returned from this function is both numeric and has a name set for each value.\n\nis.numeric( meanSepalLength )\n\n[1] TRUE\n\nnames( meanSepalLength )\n\n[1] \"setosa\"     \"versicolor\" \"virginica\" \n\n\nThen when we pass that to barplot() the column labels are set automatically (e.g., no need to set names.arg as above).\n\nbarplot( meanSepalLength, \n         xlab = \"Iris Species\",\n         ylab = \"Average Sepal Length\")\n\n\n\n\n\n\n\n\nBoxplots - High density information\nA boxplot contains a high amount of information content and is appropriate when the groupings on the x-axis are categorical. For each category, the graphical representation includes:\n\nThe median value for the raw data\nA box indicating the area between the first and third quartile (e.g,. the values enclosing the 25% - 75% of the data). The top and bottoms are often referred to as the hinges of the box.\nA notch (if requested), represents confidence around the estimate of the median.\nWhiskers extending out to shows \\(\\pm 1.5 * IQR\\) (the Inner Quartile Range)\nAny points of the data that extend beyond the whiskers are plot as points.\n\nFor legibility, we can use the functional form for the plots as well as separate out the data.frame from the columns using the optional data= argument.\n\nboxplot( Sepal.Length ~ Species, \n         data = iris, \n         notch=TRUE, \n         ylab=\"Sepal Length\" )",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Narrative Title</span>"
    ]
  },
  {
    "objectID": "classic_graphics_narrative.html#colors",
    "href": "classic_graphics_narrative.html#colors",
    "title": "6  Narrative Title",
    "section": "6.3 Colors",
    "text": "6.3 Colors\nNamed Colors -  There are 657 pre-defined, named colors built into the base R distribution. Here is a random selection of those values.\n\nrandomColors &lt;- sample( colors(), size = nrow(iris) )\nhead(randomColors)\n\n[1] \"gray32\"         \"mediumseagreen\" \"grey4\"          \"navajowhite4\"  \n[5] \"cyan1\"          \"deepskyblue\"   \n\n\nTo use these colors, you can specify them by name for either all the elements\n\nboxplot( Sepal.Length ~ Species, \n         data = iris, \n         col = randomColors[1],\n         notch=TRUE, \n         ylab=\"Sepal Length\" )\n\n\n\n\n\n\n\n\nor for each element individually.\n\nboxplot( Sepal.Length ~ Species, \n         data = iris, \n         col = randomColors[1:3],\n         notch=TRUE, \n         ylab=\"Sepal Length\" )\n\n\n\n\n\n\n\n\nHex Colors:  You can also use hexadecimal representations of colors, which is most commonly used on the internet. A hex representation of colors consists of red, green, and blue values encoded as numbers in base 16 (e.g., the single digits 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F). There are a lot of great resources on the internet for color themes that report red, green, blue and hex values. I often use the coolors.co website to look for themes that go well together for slides or presentations.\nColor Brewer Finally, there is an interesting website at colorbrewer2.org that has some interesting built-in palettes. There is an associated library that makes creating palettes for plots really easy and as you get more expreienced with R, you will find this very helpful. For quick visualizations and estimation of built-in color palettes, you can look at the website (below).\n or look at the colors in R\n\nlibrary(RColorBrewer)\ndisplay.brewer.all()\n\n\n\n\n\n\n\n\nThere are three basic kinds of palettes: divergent, qualitative, and sequential. Each of these built-in palletes has a maximum number of colors available (though as you see below we can use them to interpolate larger sets) as well as indications if the palette is safe for colorblind individuals.\n\nbrewer.pal.info\n\n         maxcolors category colorblind\nBrBG            11      div       TRUE\nPiYG            11      div       TRUE\nPRGn            11      div       TRUE\nPuOr            11      div       TRUE\nRdBu            11      div       TRUE\nRdGy            11      div      FALSE\nRdYlBu          11      div       TRUE\nRdYlGn          11      div      FALSE\nSpectral        11      div      FALSE\nAccent           8     qual      FALSE\nDark2            8     qual       TRUE\nPaired          12     qual       TRUE\nPastel1          9     qual      FALSE\nPastel2          8     qual      FALSE\nSet1             9     qual      FALSE\nSet2             8     qual       TRUE\nSet3            12     qual      FALSE\nBlues            9      seq       TRUE\nBuGn             9      seq       TRUE\nBuPu             9      seq       TRUE\nGnBu             9      seq       TRUE\nGreens           9      seq       TRUE\nGreys            9      seq       TRUE\nOranges          9      seq       TRUE\nOrRd             9      seq       TRUE\nPuBu             9      seq       TRUE\nPuBuGn           9      seq       TRUE\nPuRd             9      seq       TRUE\nPurples          9      seq       TRUE\nRdPu             9      seq       TRUE\nReds             9      seq       TRUE\nYlGn             9      seq       TRUE\nYlGnBu           9      seq       TRUE\nYlOrBr           9      seq       TRUE\nYlOrRd           9      seq       TRUE\n\n\nIt is very helpful to look at the different kinds of data palettes available and I’ll show you how to use them below when we color in the states based upon population size at the end of this document.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Narrative Title</span>"
    ]
  },
  {
    "objectID": "classic_graphics_narrative.html#annotations",
    "href": "classic_graphics_narrative.html#annotations",
    "title": "6  Narrative Title",
    "section": "6.4 Annotations",
    "text": "6.4 Annotations\nYou can easily add text onto a graph using the text() function. Here is the correlation between the sepal length and width (the function cor.test() does the statistical test).\n\ncor &lt;- cor.test( iris$Sepal.Length, iris$Sepal.Width )\ncor\n\n\n    Pearson's product-moment correlation\n\ndata:  iris$Sepal.Length and iris$Sepal.Width\nt = -1.4403, df = 148, p-value = 0.1519\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.27269325  0.04351158\nsample estimates:\n       cor \n-0.1175698 \n\n\nWe can put the correlation and the p-value on the plot\n\ncor.text &lt;- paste( \"r = \", format( cor$estimate, digits=4), \"; P = \", format( cor$p.value, digits=4 ), sep=\"\" ) \ncor.text\n\n[1] \"r = -0.1176; P = 0.1519\"\n\n\nThe we can the overlay this onto an existing plot. For the text() function, we need to give the x- and y- coordinates where you want it put onto the coordinate space of the existing graph.\n\nplot( y ~ x , \n      col=colors, \n      pch=20, \n      bty=\"n\", \n      xlab=\"Sepal Length\", ylab=\"Sepal Width\")\ntext( 7.4, 4.2, cor.text )",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Narrative Title</span>"
    ]
  },
  {
    "objectID": "ggplot_narrative.html",
    "href": "ggplot_narrative.html",
    "title": "7  A Quick Introduction to ggplot2",
    "section": "",
    "text": "7.1 Basic ggplot\nAs outlined above, the basis of this appraoch is an additive (and iterative) process of creating a graphic. This all starts with the data. For our purposes, we will use the same iris data.frame as in the previous section on base graphics.\nsummary( iris )\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50\nWe start building a graphic using the ggplot() function and passing it the data.frame object. This will initialize the graphic, though it will not plot anything.\nlibrary(ggplot2)\n\nggplot( iris )\nNext, we need to tell the plot which variables it will be using from the data.frame. For simplicity, we do not need to make special data objects with just the variables we want to plot, we can pass around the whole data.frame object and just indicate to ggplot which ones we want to use by specifying the aesthetics to be used.\nggplot( iris , aes( x=Sepal.Length ) )\nAt this point, there is enough information to make an axis in the graph because the underlying data has been identified. What has not been specified to date is the way in which we want to represent the data. To do this, we add geometries to the graph. In this case, I’m going to add a histogram\nggplot( iris, aes(x=Sepal.Length) ) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nNow we have a base graph!",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>A Quick Introduction to `ggplot2`</span>"
    ]
  },
  {
    "objectID": "ggplot_narrative.html#basic-ggplot",
    "href": "ggplot_narrative.html#basic-ggplot",
    "title": "7  A Quick Introduction to ggplot2",
    "section": "",
    "text": "The iris data",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>A Quick Introduction to `ggplot2`</span>"
    ]
  },
  {
    "objectID": "ggplot_narrative.html#aestheics-and-scope",
    "href": "ggplot_narrative.html#aestheics-and-scope",
    "title": "7  A Quick Introduction to ggplot2",
    "section": "7.2 Aestheics and Scope",
    "text": "7.2 Aestheics and Scope\nThe location of the data and the aes() determines the scope of the assignment. What I mean by this is:\n\nIf the data and aes() is in the the ggplot() function, then everything in the whole plot inherits that assignment.\nIf you put them in one or more of the components you add to ggplot() then the they are localized to only those layers.\n\nSo the following statements are all identical for this most basic of plots.\n\nggplot( iris, aes(x=Sepal.Length) ) + geom_histogram()\nggplot( iris ) + geom_historgram( aes(x=Sepal.Length) )\nggplot() + geom_histogram( aes(x=Sepal.Length), data=iris)\n\n\nIn the first case, the geom_histogram() inherits both data and aesthetics from ggplot().\n\nIn the second one, it inherits only the data but has it’s own specification for aesthetics.\nIn the last one, ggplot() only specifies the presence of a graph and all the data and aesthetics are localized within geom_histogram() function.\n\nWhere this becomes important is when we want to make more complicated graphics like the one above. The data that has the country CDI and HDI also has the names of the countries. However, only a subset of the country names are plot. This is because both the geometric layer and the text layer that has the names are using different data.frame objects.\nHere is a more simplistic example where I overlay a density plot (as a red line) on top of the histogram.\n\nggplot( iris, aes(x=Sepal.Length) ) + geom_histogram() + geom_density( col=\"red\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nBoth the geom_histogram and the geom_density use the same data and same specification for how to deal with the y-axis. However, the density is depicted as a frequency on the y-axis whereas the histogram uses counts. Also notice how the col=\"red\" is localized just for the geom_density() layer.\nWe can override the way in which geom_histogram uses the y-axis by changing the aesthetics for that particular geometric layer. Here, I’m goint to add another aes() just within the geom_histogram() function and have it treat y as the density rather than the count (yes that is two periods before and after the word density).\n\nggplot( iris, aes(x=Sepal.Length) ) + geom_histogram(aes(y=..density..)) + geom_density( col=\"red\" )\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nBy default, everything inside the ggplot() function call is inherited by all the remaining components unless it is specifically overridden. Here is a more pedantic version where only the raw data.frame is in the ggplot and the rest is in each of the geometric layers.\n\nggplot( iris ) + \n  geom_histogram( aes(x=Sepal.Length, y=..density..) ) + \n  geom_density( aes(x=Sepal.Length), col=\"red\", lwd=2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>A Quick Introduction to `ggplot2`</span>"
    ]
  },
  {
    "objectID": "ggplot_narrative.html#labels-titles",
    "href": "ggplot_narrative.html#labels-titles",
    "title": "7  A Quick Introduction to ggplot2",
    "section": "7.3 Labels & Titles",
    "text": "7.3 Labels & Titles\nJust like we added geometric layers to the plot to make histograms and densities, we do the same for labels and titles.\n\nggplot( iris,  aes(x=Sepal.Length) ) + \n  geom_histogram( aes(y=..density..), bins = 10, fill=\"lightgray\", col=\"darkgrey\" ) + \n  geom_density( col=\"red\", lwd=1.5) + \n  xlab(\"Length\") + ylab(\"Density\") + \n  ggtitle(\"Sepal Lengths for Three Iris Species\")",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>A Quick Introduction to `ggplot2`</span>"
    ]
  },
  {
    "objectID": "ggplot_narrative.html#scatter-plots",
    "href": "ggplot_narrative.html#scatter-plots",
    "title": "7  A Quick Introduction to ggplot2",
    "section": "7.4 Scatter Plots",
    "text": "7.4 Scatter Plots\nWith two columns of data, we can make the old scatter plot using the geom_point() function.\n\nggplot( iris, aes(x=Sepal.Length, y=Sepal.Width) ) + geom_point( col=\"purple\") \n\n\n\n\n\n\n\n\nIn this plot, we are hiding some of the information by having all the points be the same color and shape. We could have a geom_point for each species as follows:\n\nggplot(  ) + \n  geom_point( aes( x = Sepal.Length, y = Sepal.Width), data=iris[ 1:50,], col=\"red\") + \n  geom_point( aes( x = Sepal.Length, y = Sepal.Width), data=iris[ 51:100,], col=\"yellow\" ) + \n  geom_point( aes( x = Sepal.Length, y = Sepal.Width), data=iris[ iris$Species == \"virginica\", ], col=\"darkgreen\" ) \n\n\n\n\n\n\n\n\nBut that is a lot of typing. In cases like this, where there is a an actual column of data that we want to use to change the appearance (e.g., in this case the Species column), we can put this within the aes() directly and ggplot() will handle the specifics for you. Anything we do to reduce the amount of typing we must do is going to help us be more accurate analysts.\n\nggplot( iris, aes( x = Sepal.Length, y = Sepal.Width, col=Species) ) + geom_point()\n\n\n\n\n\n\n\n\n\n7.4.1 In or Out of aes()\nNotice in the last graph I put the name of the data column in the aesthetic but have the color (col) within the aes() function call in the graph before that, I put color outside of the aes() in the geom_point() function. What gives? Here is a simple rule.\n\nIf information from within the data.frame is needed to customize the display of data then it must be designated within the aes(), whereas if the display of the data is to be applied to the entire geometric layer, it is specified outside of the aes() call.\n\nHere is an example, where I have the color of the shapes determined by a value in the data.frame but have the shape2 applied to all the points, independent of any data in the data.frame.\n\nggplot( iris ) + geom_point(aes( x = Sepal.Length, y = Sepal.Width, col=Species), shape=5)\n\n\n\n\n\n\n\n\nWe can build these things in an iterative fashion making things easier to read. In what follows I will use the basic plot from above but assign it to the variable p as I add things to it. It can be as iterative as you like and you can add a bunch of stuff and wait until the end to display it.\n\np &lt;- ggplot( iris ) \np &lt;- p + geom_point(aes( x = Sepal.Length, y = Sepal.Width, col=Species, shape=Species), size=3, alpha=0.75 ) \np &lt;- p + xlab(\"Sepal Length\") \np &lt;- p + ylab(\"Sepal Width\")\n\nThe overall class of the plot varible is\n\nclass(p)\n\n[1] \"gg\"     \"ggplot\"\n\n\nAnd there is no plot output until we display it specifically.\n\np",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>A Quick Introduction to `ggplot2`</span>"
    ]
  },
  {
    "objectID": "ggplot_narrative.html#themes",
    "href": "ggplot_narrative.html#themes",
    "title": "7  A Quick Introduction to ggplot2",
    "section": "7.5 Themes",
    "text": "7.5 Themes\nThe overall coloration of the plot is determined by the theme.\n\np + theme_bw()\n\n\n\n\n\n\n\n\n\np + theme_dark()\n\n\n\n\n\n\n\n\n\np + theme_minimal()\n\n\n\n\n\n\n\n\n\np + theme_linedraw()\n\n\n\n\n\n\n\n\n\np + theme_void()\n\n\n\n\n\n\n\n\nYou can even define your own themes to customize all the text and lines.\nOne thing that I like to do is to specify a default theme for all my plots. You can accomplish this using theme_set() and from this point forward, this theme will be used as the default (again, we need to try as hard as possible to minimzie the amount of typing we do to minimize the amount of mistakes we make).\n\ntheme_set( theme_bw() )",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>A Quick Introduction to `ggplot2`</span>"
    ]
  },
  {
    "objectID": "ggplot_narrative.html#boxplots",
    "href": "ggplot_narrative.html#boxplots",
    "title": "7  A Quick Introduction to ggplot2",
    "section": "7.6 Boxplots",
    "text": "7.6 Boxplots\n\nggplot( iris, aes( x = Sepal.Length) ) + geom_boxplot( notch=TRUE )\n\n\n\n\n\n\n\n\n\nggplot( iris, aes(x=Species, y=Sepal.Length) )  + geom_boxplot( notch=TRUE )",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>A Quick Introduction to `ggplot2`</span>"
    ]
  },
  {
    "objectID": "ggplot_narrative.html#overlays",
    "href": "ggplot_narrative.html#overlays",
    "title": "7  A Quick Introduction to ggplot2",
    "section": "7.7 Overlays",
    "text": "7.7 Overlays\nJust like in the previous\n\np &lt;- ggplot( iris, aes(Sepal.Length, Sepal.Width) ) + \n  geom_point(col=\"red\") + \n  xlab(\"Sepal Length\") + \n  ylab(\"Sepal Width\")\n\nThe order by which you add the components to the ggplot() will determine the order of the layers from bottom to top—the. Layers added earlier will be covered by content in layers that are added later. Compare the following plot that takes the length and width of the sepals and overlays a linear regression line over the top.\n\np + geom_point(col=\"red\") + \n  stat_smooth( formula = y ~ x, method=\"lm\", alpha=1.0)\n\n\n\n\n\n\n\n\nCompare that plot to the one below. Notice how puting stat_smooth() in front of the call to geom_point() layes the regression smoothing line and error zone underneath the points.\n\np + stat_smooth(formula = y ~ x, method=\"lm\", alpha=1.0) + \n  geom_point(col=\"red\")",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>A Quick Introduction to `ggplot2`</span>"
    ]
  },
  {
    "objectID": "ggplot_narrative.html#labeling",
    "href": "ggplot_narrative.html#labeling",
    "title": "7  A Quick Introduction to ggplot2",
    "section": "7.8 Labeling",
    "text": "7.8 Labeling\nWe can create two kinds of annotations, text on the raw graph and text associated with some of the points. Labels of the first kind can be added direclty by placing raw data inside the aes() function.\nI’ll start by taking the correlation between sepal width and length.\n\ncor &lt;- cor.test( iris$Sepal.Length, iris$Sepal.Width )\ncor\n\n\n    Pearson's product-moment correlation\n\ndata:  iris$Sepal.Length and iris$Sepal.Width\nt = -1.4403, df = 148, p-value = 0.1519\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.27269325  0.04351158\nsample estimates:\n       cor \n-0.1175698 \n\n\nAnd then grab the raw data from it and make a message.\n\ncor.text &lt;- paste( \"r = \", format( cor$estimate, digits=4), \"; P = \", format( cor$p.value, digits=4 ), sep=\"\" ) \ncor.text\n\n[1] \"r = -0.1176; P = 0.1519\"\n\n\nThat I’ll stick onto the graph directly\n\np + geom_text( aes(x=7.25, y=4.25, label=cor.text))\n\nWarning in geom_text(aes(x = 7.25, y = 4.25, label = cor.text)): All aesthetics have length 1, but the data has 150 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\nAlternatively, we may want to label specific points. Here I find the mean values for each species.\n\nmean_Length &lt;- by( iris$Sepal.Length, iris$Species, mean, simplify = TRUE)\nmean_Width &lt;- by( iris$Sepal.Width, iris$Species, mean, simplify = TRUE)\nmean_Values &lt;- data.frame(  Species = levels( iris$Species), \n                            Sepal.Length = as.numeric( mean_Length ), \n                            Sepal.Width = as.numeric( mean_Width ) ) \nmean_Values\n\n     Species Sepal.Length Sepal.Width\n1     setosa        5.006       3.428\n2 versicolor        5.936       2.770\n3  virginica        6.588       2.974\n\n\nTo plot and label these mean values, I’m going to use two steps. First, since I named the columns of the new data.frame the same as before, we can just inherit the aes() but substitute in this new data.frame and add label=Species to the the aesthetics.\n\np + geom_text( data=mean_Values, aes(label=Species) )\n\n\n\n\n\n\n\n\nBut that is a bit messy. Here is a slick helper library for that that will try to minimize the overlap.\n\nlibrary( ggrepel ) \np + geom_label_repel( data=mean_Values, aes(label=Species) )\n\n\n\n\n\n\n\n\nSlick.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>A Quick Introduction to `ggplot2`</span>"
    ]
  },
  {
    "objectID": "ggplot_narrative.html#questions",
    "href": "ggplot_narrative.html#questions",
    "title": "7  A Quick Introduction to ggplot2",
    "section": "7.9 Questions",
    "text": "7.9 Questions\nIf you have any questions for me specifically on this topic, please post as an Issue in your repository, otherwise consider posting to the discussion board on Canvas.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>A Quick Introduction to `ggplot2`</span>"
    ]
  },
  {
    "objectID": "ggplot_narrative.html#footnotes",
    "href": "ggplot_narrative.html#footnotes",
    "title": "7  A Quick Introduction to ggplot2",
    "section": "",
    "text": "Literally, we add these toghter using the plus ‘+’ sign just like we were going to develop an equation.↩︎\nThe shapes are the same as the pch offerings covered in the lecture on graphing using Base R routines here.↩︎",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>A Quick Introduction to `ggplot2`</span>"
    ]
  },
  {
    "objectID": "points_narrative.html",
    "href": "points_narrative.html",
    "title": "8  Spatial Point Data",
    "section": "",
    "text": "8.1 Learning Objectives\nThis topics is the first",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Spatial Point Data</span>"
    ]
  },
  {
    "objectID": "points_narrative.html#learning-objectives",
    "href": "points_narrative.html#learning-objectives",
    "title": "8  Spatial Point Data",
    "section": "",
    "text": "Describe the importance of Ellipsoids & Datum in spatial data.\nUse both sf & ggplot in visualizing point data.\nBe able to transform point data from one projection to another.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Spatial Point Data</span>"
    ]
  },
  {
    "objectID": "points_narrative.html#ellipsoids",
    "href": "points_narrative.html#ellipsoids",
    "title": "8  Spatial Point Data",
    "section": "8.2 Ellipsoids",
    "text": "8.2 Ellipsoids\nUnless you are in PHYS 101, the earth is not a perfect sphere (😉). It is an irregularly shaped object that we need to be able to characterize if we are going to develop a system of placing points onto it and doing things such as measuring distance, finding watersheds, or defining boundaries.\nThere has been a long history of ellipsoid research, all of which has been sought to increase our ability to map and move across the earth. The following table gives some historical and contemporary ellipsoids.\n\n\n\n\n\n\n\n\n\nEllipsoid\nEquatorial Radius (m)\nPolar Radius (m)\nUsed\n\n\n\n\nMaupertuis (1738)\n6,397,300\n6,363,806.283\nFrance\n\n\nPlessis (1817)\n6,376,523.0\n6,355,862.9333\nFrance\n\n\nEverest (1830)\n6,377,299.365\n6,356,098.359\nIndia\n\n\nEverest 1830 Modified (1967)\n6,377,304.063\n6,356,103.0390\nWest Malaysia & Singapore\n\n\nEverest 1830 (1967 Definition)\n6,377,298.556\n6,356,097.550\nBrunei & East Malaysia\n\n\nAiry (1830)\n6,377,563.396\n6,356,256.909\nBritain\n\n\nBessel (1841)\n6,377,397.155\n6,356,078.963\nEurope, Japan\n\n\nClarke (1866)\n6,378,206.4\n6,356,583.8\nNorth America\n\n\nClarke (1878)\n6,378,190\n6,356,456\nNorth America\n\n\nClarke (1880)\n6,378,249.145\n6,356,514.870\nFrance, Africa\n\n\nHelmert (1906)\n6,378,200\n6,356,818.17\nEgypt\n\n\nHayford (1910)\n6,378,388\n6,356,911.946\nUSA\n\n\nInternational (1924)\n6,378,388\n6,356,911.946\nEurope\n\n\nKrassovsky (1940)\n6,378,245\n6,356,863.019\nUSSR, Russia, Romania\n\n\nWGS66 (1966)\n6,378,145\n6,356,759.769\nUSA/DoD\n\n\nAustralian National (1966)\n6,378,160\n6,356,774.719\nAustralia\n\n\nNew International (1967)\n6,378,157.5\n6,356,772.2\n\n\n\nGRS-67 (1967)\n6,378,160\n6,356,774.516\n\n\n\nSouth American (1969)\n6,378,160\n6,356,774.719\nSouth America\n\n\nWGS-72 (1972)\n6,378,135\n6,356,750.52\nUSA/DoD\n\n\nGRS-80 (1979)\n6,378,137\n6,356,752.3141\nGlobal ITRS\n\n\nWGS-84 (1984)\n6,378,137\n6,356,752.3142\nGlobal GPS\n\n\nIERS (1989)\n6,378,136\n6,356,751.302\n\n\n\nIERS (2003)\n6,378,136.6\n6,356,751.9\n\n\n\n\nThe most common ones you will probably run across include GRS80/NAD83 (derived from satellite measurements of the distance of the surface to the core of the planet ) and WGS-84 (an ellipsoid based upon GPS).\n\n8.2.1 Example Data\nTo examine the differences between ellipsoids, let’s load in some data first. Here are some point data that can be interpreted as polygons and represent the lower 48 states of the US.\n\nstates &lt;- map_data(\"state\")\nhead( states )\n\n       long      lat group order  region subregion\n1 -87.46201 30.38968     1     1 alabama      &lt;NA&gt;\n2 -87.48493 30.37249     1     2 alabama      &lt;NA&gt;\n3 -87.52503 30.37249     1     3 alabama      &lt;NA&gt;\n4 -87.53076 30.33239     1     4 alabama      &lt;NA&gt;\n5 -87.57087 30.32665     1     5 alabama      &lt;NA&gt;\n6 -87.58806 30.32665     1     6 alabama      &lt;NA&gt;\n\n\nEach row is a point that is associated with a group (in this case the state) and is plot in a specific order (to make the outline of the state). There are 15,537 points required to make the plot, with the following 49 regions.\n\nunique( states$region )\n\n [1] \"alabama\"              \"arizona\"              \"arkansas\"            \n [4] \"california\"           \"colorado\"             \"connecticut\"         \n [7] \"delaware\"             \"district of columbia\" \"florida\"             \n[10] \"georgia\"              \"idaho\"                \"illinois\"            \n[13] \"indiana\"              \"iowa\"                 \"kansas\"              \n[16] \"kentucky\"             \"louisiana\"            \"maine\"               \n[19] \"maryland\"             \"massachusetts\"        \"michigan\"            \n[22] \"minnesota\"            \"mississippi\"          \"missouri\"            \n[25] \"montana\"              \"nebraska\"             \"nevada\"              \n[28] \"new hampshire\"        \"new jersey\"           \"new mexico\"          \n[31] \"new york\"             \"north carolina\"       \"north dakota\"        \n[34] \"ohio\"                 \"oklahoma\"             \"oregon\"              \n[37] \"pennsylvania\"         \"rhode island\"         \"south carolina\"      \n[40] \"south dakota\"         \"tennessee\"            \"texas\"               \n[43] \"utah\"                 \"vermont\"              \"virginia\"            \n[46] \"washington\"           \"west virginia\"        \"wisconsin\"           \n[49] \"wyoming\"             \n\n\nFortunately for us, our old friend ggplot has a bit of magic that can do this kind of plotting for us.\n\nlibrary( ggplot2 )\nggplot( states, aes( x = long, \n                     y = lat,\n                     group = group ) ) + \n  geom_polygon( fill = \"lightgray\", \n                color = \"black\", \n                lwd = 0.25) + \n  theme_void() -&gt; p\n\n\n\n8.2.2 Azimuth Projections\nAn Azimuth Projection is one that is formed by a 2-dimensional plane that is tangential to the surface of the earth at example one point. This point may be polar (north or south pole) or oblique (e.g., over Richmond, Virginia).\n\n\n\n\nAzequidistant\n\n\n\nWe can apply different ellipsoids to the map when we plot it by adjusting the coordinate space it is plot within using the coord_map() modification. For a whole list of available projections, see ?mapproject.\n\np + coord_map( \"azequalarea\")\n\n\n\n\n\n\n\n\n\n\n8.2.3 Cylindrical Projection\nA cylindrical projection is one where a cylinder is wrapped around the earth creating straight lines for all parallel away from the equator.\n\n\n\n\nCylindrical Projection\n\n\n\n\np + coord_map(\"cylindrical\")\n\n\n\n\n\n\n\n\n\n\n8.2.4 Conic Projections\nConic projections are symmetric around the prime meridian and all parallels are segments of conecntric circles.\n\n\n\n\nConic Projection\n\n\n\n\np + coord_map( \"conic\", lat0 = 30)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Spatial Point Data</span>"
    ]
  },
  {
    "objectID": "points_narrative.html#datum",
    "href": "points_narrative.html#datum",
    "title": "8  Spatial Point Data",
    "section": "8.3 Datum",
    "text": "8.3 Datum\nOnce we have an ellipsoid model to work with we must define a DATUM type that will represent the coordiante system used. Two common DATUM types include:\n\nLongitude & Latitude - The East/West & North/South position on the surface of the earth.\n\nPrime Meridian (0° Longitude) passes thorugh the Royal Observatory in Greenwich England, with positive values of longitude to the east and negative to the west.\nEquator (0° Latitude) and is defined as the point on the planet where both northern and southern hemisphers have equal amounts of day and night at the equinox (Sept. 21 & March 21).\nRichmond, Virginia: 37.533333 Latitude, -77.466667 Longitude\n\nUniversal Trans Mercator - A division of the earth into 60 zones (~6°longitude each, labeled 01 - 60) and 20 bands each of which is ~8° latitude (labeled C-X excluding I & O with A & B dividing up Antartica). See image here.\n\nCoordinates include Zone & band designation as well as coordinates in Easting and Northing (planar coordinates within the zone) measured in meters.\nRichmond, Virginia: 18S 282051 4156899\n\n\n\n\n\n\n⚠️\n\n\n \n\n\nYou must set both the ellipsoid and datum to be EXACTLY THE SAME for all of your data before you can do any work with it. If they are not on the same lumpy bumpy planet or in the same coordinate system, you will be screwed (that is a technical term).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Spatial Point Data</span>"
    ]
  },
  {
    "objectID": "points_narrative.html#sf-objects",
    "href": "points_narrative.html#sf-objects",
    "title": "8  Spatial Point Data",
    "section": "10.1 sf Objects",
    "text": "10.1 sf Objects\nSimple Features (hereafter abbreviated as sf) are an open standard developed by the Open Geospatial Consortium (OGC). They define the following basic types:\n\nPOINT\n\nLINESTRING\nPOLYGON\n\nMULTIPOINT\nMULTILINESTRING\nMULTIPOLYGON\nGEOMETRYCOLLECTION\n\nEach of these basic types can be represented within a single column of a data.frame. To do this, we need to tell the conversion function st_as_sf() which columns to consider as the datum and which ellipsoid to use.\n\nlibrary( sf )\ndata %&gt;%\n  st_as_sf( coords=c(\"Longitude\",\"Latitude\"),\n            crs = 4326 ) -&gt; data\nhead( data )\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -110.951 ymin: 23.2855 xmax: -109.8507 ymax: 24.21441\nGeodetic CRS:  WGS 84\n# A tibble: 6 × 8\n  Site  Males Females Suitability MFRatio GenVarArapat GenVarEuphli\n  &lt;chr&gt; &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 Aqu      12       9       0.722   1.33         0.120       0.0968\n2 73       11       5       0.146   2.2          0.137       0.253 \n3 157      26      30       0.881   0.867        0.150       0.191 \n4 153      35      41       0.732   0.854        0.333       0.276 \n5 163      21      21       0.433   1            0.298       0.338 \n6 48       18      27       0.620   0.667        0.115       0.213 \n# ℹ 1 more variable: geometry &lt;POINT [°]&gt;\n\n\nThis conversion to an sf object adds attributes to the data.frame and tibble object.\n\nclass( data )\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nThis additional sf attributes gives it more qualities such as a bounding box (e.g., the area within which all the poitns exist)\n\nst_bbox( data )\n\n      xmin       ymin       xmax       ymax \n-114.29353   23.28550 -109.32700   29.32541 \n\n\nDistances between objects.\n\nst_distance( data[1,], data[2,])\n\nUnits: [m]\n        [,1]\n[1,] 84376.8\n\n\nAs well as complex geospatial operations such as finding the convex hull (the minimal area containing all poitns).\n\ndata %&gt;%\n  st_union() %&gt;%\n  st_convex_hull() -&gt; hull\nhull\n\nGeometry set for 1 feature \nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -114.2935 ymin: 23.2855 xmax: -109.327 ymax: 29.32541\nGeodetic CRS:  WGS 84\n\n\nPOLYGON ((-114.2935 29.32541, -113.9914 28.6605...\n\n\nthe center of the all the points.\n\nhull %&gt;%\n  st_centroid()\n\nGeometry set for 1 feature \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -111.3417 ymin: 26.37741 xmax: -111.3417 ymax: 26.37741\nGeodetic CRS:  WGS 84\n\n\nPOINT (-111.3417 26.37741)\n\n\nand the area enclosed by all the points (for various units).\n\nlibrary( units )\n\nudunits database from /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/units/share/udunits/udunits2.xml\n\nhull %&gt;%\n  st_area() %&gt;%\n  set_units( km^2 )\n\n122130.5 [km^2]\n\n\n\n10.1.1 Reprojecting\nIn addition to the operations above, properly created sf objects can easily be projected from one CRS into another (epsg 6372 is a common projection covering Mexico based upon the GRS80 elipsoid and the latest ITRF2008 datum standard based on the meter)4.\n\ndata %&gt;%\n  st_transform( 6372 ) %&gt;%\n  st_bbox()\n\n   xmin    ymin    xmax    ymax \n1307745 1274010 1773676 1968473 \n\n\nAgain, do this first to all your data to make sure it is put into a proper projection (and most of your headaches will disappear).\n\n\n10.1.2 Plotting sf Objects\nAnalogous to the duality between built-in R plotting and ggplot approaches, we can use either of these frameworks to plot sf objects.\nAs built-in objects, a sf data set that has a geometry coordinate is intrinsically linked to all the other data columns. If we plot the entire data frame, we see that for each non-geometry data column, we create an individual plot.\n\nplot( data )\n\n\n\n\n\n\n\n\nThe data with the data.frame can be accessed as normal.\n\nplot( data$Suitability )\n\n\n\n\n\n\n\n\nBut if we plot it using the square brackets and names of dat columns, we can link the geometry column to it and plot it as a spatial representation of those data (and adorn it with the normal plot() upgrades accordingly).\n\nplot( data[\"Suitability\"], pch=16, cex=2)\n\n\n\n\n\n\n\n\nPerhaps not surprisingly, ggplot() also works the same way, however, the geospatial coordiantes for the plot aare taken care of using geom_sf() and you are left with definining which of the data columns you want to put into the plot as a component of the aes() definition.\n\nggplot( data, aes(color=Suitability) ) + \n  geom_sf( )\n\n\n\n\n\n\n\n\nIt works the same ways for lables.\n\nggplot( data ) + \n  geom_sf_text( aes(label=Site) ) + \n  theme_void() + \n  coord_map()\n\nWarning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not\ngive correct results for longitude/latitude data",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Spatial Point Data</span>"
    ]
  },
  {
    "objectID": "points_narrative.html#footnotes",
    "href": "points_narrative.html#footnotes",
    "title": "8  Spatial Point Data",
    "section": "",
    "text": "Tobler, W. R. 1970. Economic Geography, 46, 234–240.↩︎\nTranslation from one CRS to another in all GIS software is handled by the open source proj.org library.↩︎\nThe EPSG standard was originally created in 1985 by the https://en.wikipedia.org/wiki/European_Petroleum_Survey_Group and made public in 1993.↩︎\nThis standard is defined by Sistema Nacional de Información Estadística y Geográfica.↩︎\nThis is because if we use the normal procedures, we mess up the order in which everything is plot in geom_polygon(), try it and see.↩︎",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Spatial Point Data</span>"
    ]
  },
  {
    "objectID": "raster_narrative.html",
    "href": "raster_narrative.html",
    "title": "9  Raster Data Narrative",
    "section": "",
    "text": "9.1 Making Rasters de novo\nA raster is simply a matrix with rows and columns and each element has a value associated with it. You can create a raster de novo by making a matrix of data and filling it with values, then turning it into a raster.\nHere I make a raster with random numbrers selected from the Poisson Distribution (fishy, I know) using the rpois() function. I then turn it into a matrix with 7 rows (and 7 columns).\nvals &lt;- rpois(49, lambda=12)\nx &lt;- matrix( vals, nrow=7)\nx\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]   15   18   13   13   11   10    8\n[2,]   10    8    9   10   10    9   15\n[3,]   15   10    8   12   12   13   11\n[4,]   18   10   11    7   15   18    5\n[5,]   14   10   13    5    5    7   15\n[6,]   11    9    9   13   14    9   13\n[7,]   12   15   11   11   12   10    8\nWhile we haven’t used matrices much thus far, it is a lot like a data.frame with respect to getting and setting values using numerical indices. For example, the value of the 3rd row and 5th column is:\nx[3,5]\n\n[1] 12\nTo convert this set of data, as a matrix, into a geospatially referenced raster() object we do the following:\nr &lt;- raster( x )\nr\n\nclass      : RasterLayer \ndimensions : 7, 7, 49  (nrow, ncol, ncell)\nresolution : 0.1428571, 0.1428571  (x, y)\nextent     : 0, 1, 0, 1  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : 5, 18  (min, max)\nNotice that when I plot it out, it does not show the data, but a summary of the data along with some key data about the contents, including:\n- A class definition\n- The dimensions of the underlying data matrix,\n- The resolution (e.g., the spatial extent of the sides of each pixel). Since we have no CRS here, it is equal to \\(nrows(x)^{-1}\\) and \\(ncols(x)^{-1}\\).\n- The extent (the bounding box) and again since we do not have a CRS defined it just goes from \\(0\\) to \\(1\\). - The crs (missing) - The source can be either memory if the raster is not that big or out of memory if it is just referencing.\nIf these data represent something on the planet, we can assign the dimensions and CRS values to it and use it in our normal day-to-day operations.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Raster Data Narrative</span>"
    ]
  },
  {
    "objectID": "raster_narrative.html#loading-rasters-from-files-or-urls",
    "href": "raster_narrative.html#loading-rasters-from-files-or-urls",
    "title": "9  Raster Data Narrative",
    "section": "9.2 Loading Rasters from Files or URLs",
    "text": "9.2 Loading Rasters from Files or URLs\nWe can also grab a raster object from the filesystem or from some online repository by passing the link to the raster() function. Here is the elevation, in meters, of the region in which Mexico is found. To load it in, pass the url.\n\nurl &lt;- \"https://github.com/DyerlabTeaching/Raster-Data/raw/main/data/alt_22.tif\"\nr &lt;- raster( url )\nr\n\nclass      : RasterLayer \ndimensions : 3600, 3600, 12960000  (nrow, ncol, ncell)\nresolution : 0.008333333, 0.008333333  (x, y)\nextent     : -120, -90, 0, 30  (xmin, xmax, ymin, ymax)\ncrs        : +proj=longlat +datum=WGS84 +no_defs \nsource     : alt_22.tif \nnames      : alt_22 \nvalues     : -202, 5469  (min, max)\n\n\nNotice that this raster has a defined CRS and as such it is projected and the extent relates to the units of the datum (e.g., from -120 to -90 degrees longitude and 0 to 30 degrees latitude).\nIf we plot it, we can see the whole raster.\n\nplot(r)\n\n\n\n\n\n\n\n\nNow, this raster is elevation where there is land but where there is no land, it is full of NA values. As such, there is a ton of them.\n\nformat( sum( is.na( values(r) ) ), big.mark = \",\" )\n\n[1] \"10,490,650\"",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Raster Data Narrative</span>"
    ]
  },
  {
    "objectID": "raster_narrative.html#cropping",
    "href": "raster_narrative.html#cropping",
    "title": "9  Raster Data Narrative",
    "section": "9.3 Cropping",
    "text": "9.3 Cropping\nOne of the first things to do is to crop the data down to represent the size and extent of our study area. If we over 10 million missing data points (the ocean) and most of Mexico in this raster above but we are only working with sites in Baja California (Norte y Sur), we would do well to excise (or crop) the raster to only include the area we are interested in working with.\nTop do this, we need to figure out a bounding box (e.g., the minimim and maximum values of longitude and latitude that enclose our data). Let’s assume we are working with the Beetle Data from the Spatial Points Slides and load in the Sex-biased dispersal data set and use those points as a starting estimate of the bounding box.\n\nlibrary( sf )\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\nlibrary( tidyverse )\nbeetle_url &lt;- \"https://raw.githubusercontent.com/dyerlab/ENVS-Lectures/master/data/Araptus_Disperal_Bias.csv\"\n\nread_csv( beetle_url ) %&gt;%\n  st_as_sf( coords=c(\"Longitude\",\"Latitude\"), crs=4326 ) -&gt; beetles\n\nRows: 31 Columns: 9\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Site\ndbl (8): Males, Females, Suitability, MFRatio, GenVarArapat, GenVarEuphli, L...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsummary( beetles )\n\n     Site               Males          Females       Suitability    \n Length:31          Min.   : 9.00   Min.   : 5.00   Min.   :0.0563  \n Class :character   1st Qu.:16.00   1st Qu.:15.50   1st Qu.:0.2732  \n Mode  :character   Median :21.00   Median :21.00   Median :0.3975  \n                    Mean   :25.68   Mean   :23.52   Mean   :0.4276  \n                    3rd Qu.:31.50   3rd Qu.:29.00   3rd Qu.:0.5442  \n                    Max.   :64.00   Max.   :63.00   Max.   :0.9019  \n    MFRatio        GenVarArapat     GenVarEuphli             geometry \n Min.   :0.5938   Min.   :0.0500   Min.   :0.0500   POINT        :31  \n 1st Qu.:0.8778   1st Qu.:0.1392   1st Qu.:0.1777   epsg:4326    : 0  \n Median :1.1200   Median :0.2002   Median :0.2171   +proj=long...: 0  \n Mean   :1.1598   Mean   :0.2006   Mean   :0.2203                     \n 3rd Qu.:1.3618   3rd Qu.:0.2592   3rd Qu.:0.2517                     \n Max.   :2.2000   Max.   :0.3379   Max.   :0.5122                     \n\n\nNow, we can take the bounding box of these points and get a first approximation.\n\nbeetles %&gt;% st_bbox()\n\n      xmin       ymin       xmax       ymax \n-114.29353   23.28550 -109.32700   29.32541 \n\n\nOK, so this is the strict bounding box for these points. This means that the minimum and maximum values for these points are defined by the original locations—for both the latitude and longitude (both minimum and maximum)—we have sites on each of the edges. This is fine here but we could probably add a little bit of a buffer around that bounding box so that we do not have our sites on the very edge of the plot. We can do this by either eyeballing-it to round up to some reasonable area around the points or apply a buffer (st_buffer) to the union of all the points with some distance and then take the boounding box. I’ll go for the former and make it into an extent object.\n\nbaja_extent &lt;- extent( c(-116, -109, 22, 30 ) )\nbaja_extent\n\nclass      : Extent \nxmin       : -116 \nxmax       : -109 \nymin       : 22 \nymax       : 30 \n\n\nThen we can crop() the original raster using this extent object to create our working raster. I can then dump my points onto the same raster plot by indicaating add=TRUE\n\nalt &lt;- crop( r, baja_extent )\nplot(alt)\nplot( beetles[\"Suitability\"], pch=16, add=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n⚠️\n\n\n\n   \n\n\nYou need to be careful here. When you use built-in graphics processes in a markdown document such as this and intend to add subsequent plots to an existing plot you cannot run the lines individual. They must be all executed as the whole chunk. So there is no CTRL/CMD + RETURN action here, it will plot the first one and then complain throughout the remaining ones saying something like plot.new has not been called yet. So you have to either knit the whole document or just run the whole chunk to get them to overlay.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Raster Data Narrative</span>"
    ]
  },
  {
    "objectID": "raster_narrative.html#masking",
    "href": "raster_narrative.html#masking",
    "title": "9  Raster Data Narrative",
    "section": "9.4 Masking",
    "text": "9.4 Masking\nThere is another way to grab just a portion of the raster—similar to cropping—which is to mask. A mask will not change the size of the raster but just put NA values in the cells that are not in the are of interest. So if we were to just mask above, it would never actually reduce the size of the raster, just add a lot more NA values. However, the setup is the same.\n\nbeetles %&gt;%\n  filter( Site != 32 ) %&gt;%\n  st_union() %&gt;%\n  st_buffer( dist = 1 ) %&gt;%\n  st_convex_hull() -&gt; hull\n\nbaja &lt;- mask( alt, as(hull, \"Spatial\"))\nbaja\n\nclass      : RasterLayer \ndimensions : 960, 840, 806400  (nrow, ncol, ncell)\nresolution : 0.008333333, 0.008333333  (x, y)\nextent     : -116, -109, 22, 30  (xmin, xmax, ymin, ymax)\ncrs        : +proj=longlat +datum=WGS84 +no_defs \nsource     : memory\nnames      : alt_22 \nvalues     : -202, 1838  (min, max)\n\n\nAnd it looks like.\n\nplot(baja)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Raster Data Narrative</span>"
    ]
  },
  {
    "objectID": "raster_narrative.html#plotting-with-ggplot",
    "href": "raster_narrative.html#plotting-with-ggplot",
    "title": "9  Raster Data Narrative",
    "section": "9.5 Plotting with GGPlot",
    "text": "9.5 Plotting with GGPlot\nAs you may suspect, our old friend ggplot has some tricks up its sleave for us. The main thing here is that ggplot requires a data.frame object and a raster is not a data.frame — Unless we turn it into one (hehehe) using a cool function called rasterToPoints(). This takes the cells of the raster (and underlying matrix) and makes points from it.\n\nalt %&gt;%\n  rasterToPoints() %&gt;%\n  head()\n\n             x        y alt_22\n[1,] -115.7958 29.99583     55\n[2,] -115.7875 29.99583    126\n[3,] -115.7792 29.99583     94\n[4,] -115.7708 29.99583     99\n[5,] -115.7625 29.99583    106\n[6,] -115.7542 29.99583    120\n\n\nHowever, they are not a data.frame but a matrix.\n\nalt %&gt;%\n  rasterToPoints() %&gt;%\n  class()\n\n[1] \"matrix\" \"array\" \n\n\nSo, if we are going to use this, w need to transform it from a matrix object into a data.frame object. We can do this using the as.data.frame() function. Remember from the lecture on data.frame objects that we can coerce columns of data (either matrix or array) into a data.frame this way.\nSo here it is in one pipe, using the following tricks:\n- Converting raster to points and then to data.frame so it will go into ggplot\n- Renaming the columns of data I am going to keep so I don’t have to make xlab and ylab\n\nalt %&gt;%\n  rasterToPoints() %&gt;%\n  as.data.frame() %&gt;% \n  transmute(Longitude=x,\n            Latitude=y,\n            Elevation=alt_22)  -&gt; alt.df\nhead( alt.df )\n\n  Longitude Latitude Elevation\n1 -115.7958 29.99583        55\n2 -115.7875 29.99583       126\n3 -115.7792 29.99583        94\n4 -115.7708 29.99583        99\n5 -115.7625 29.99583       106\n6 -115.7542 29.99583       120\n\n\nThen we can plot it by:\n- Plotting it using geom_raster() and setting the fill color to the value of elevation. - Making the coordinates equal (e.g., roughtly equal in area for longitude and latitude), and - Applying only a minimal theme.\n\nalt.df %&gt;%\n  ggplot()  + \n  geom_raster( aes( x = Longitude, \n                    y = Latitude, \n                    fill = Elevation) ) + \n  coord_equal() +\n  theme_minimal() -&gt; baja_elevation\n\nbaja_elevation\n\n\n\n\n\n\n\n\nThat looks good but we should probably do something with the colors. There is a built-in terrain.colors() and tell ggplot to use this for the fill gradient.\n\nbaja_elevation + \n  scale_fill_gradientn( colors=terrain.colors(100))\n\n\n\n\n\n\n\n\nOr you can go dive into colors and set your own, you can set up your own gradient for ggplot using independent colors and then tell it where the midpoint is along that gradient and it will do the right thing©.\n\nbaja_elevation + \n  scale_fill_gradient2( low = \"darkolivegreen\",\n                        mid = \"yellow\",\n                        high = \"brown\", \n                        midpoint = 1000 ) -&gt; baja_map\nbaja_map\n\n\n\n\n\n\n\n\nNow that looks great. Now, how about overlaying the points onto the plot and indicate the size of the point by the ♂♀ ratio.\n\nbaja_map + \n  geom_sf( aes(size = MFRatio ), \n           data = beetles, \n           color = \"dodgerblue2\",\n           alpha = 0.75) \n\n\n\n\n\n\n\n\nNow that looks nice.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Raster Data Narrative</span>"
    ]
  },
  {
    "objectID": "raster_narrative.html#identifying-points",
    "href": "raster_narrative.html#identifying-points",
    "title": "9  Raster Data Narrative",
    "section": "9.6 Identifying Points",
    "text": "9.6 Identifying Points\nYou can get some information from a raster plot interactively by using the click function. This must be done with an active raster plot. After that, you use the click() function to grab what you need. Your mouse will turn from an arrow into a cross hair and you can position it where you like and get information such as the corrdinates (spatial) of the point and the value of the raster pixel at that location.\nIf you do not specify n= in the function then it will continue to collect data until you click outside the graphing area. If you set id=TRUE it will plot the number of the point onto the map so you can see where you had clicked. Since this is interactive, you will not see the process when you execute the code below, but it will look like.\n\nplot( alt )\nclick(alt, xy=TRUE, value=TRUE, n=3 ) -&gt; points\n\n\n\n\nmap with points\n\n\nHere are what the points look like.\n\npoints\n\n          x        y value\n1 -113.6292 28.45417   870\n2 -112.4792 26.85417  1185\n3 -111.2458 24.83750   135\n4 -109.9958 23.48750  1145\n\n\nI’m going to rename the column names\n\npoints %&gt;%\n  transmute( Longitude = x,\n             Latitude = y,\n             Value = value) -&gt; sites\n\nAnd then I can plot those points (using geom_point()) onto our background map.\n\nbaja_map + \n  geom_point( aes(x = Longitude,\n                  y = Latitude, \n                  size = Value), data=sites, color=\"red\") \n\n\n\n\n\n\n\n\nMexellent!",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Raster Data Narrative</span>"
    ]
  },
  {
    "objectID": "raster_narrative.html#reprojecting-rasters",
    "href": "raster_narrative.html#reprojecting-rasters",
    "title": "9  Raster Data Narrative",
    "section": "9.7 Reprojecting Rasters",
    "text": "9.7 Reprojecting Rasters\nJust like points, we can reproject the entire raster using the projectRaster function. HJere I am going to project the raster into UTM Zone 12N, a common projection for this part of Mexico from epsg.io.\nUnfortunatly, the raster library does not use epsg codes so we’ll have to use the large description of that projection. See the page for this projection and scroll down to the proj.4 definition.\n\nnew.proj &lt;- \"+proj=utm +zone=12 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \"\n\nCopy this into a character variable and then use the projectRaster() function and assign that new value as the CRS.\n\nalt.utm &lt;- projectRaster( alt, crs=new.proj)\nplot( alt.utm, xlab=\"Easting\", ylab=\"Northing\" )\n\n\n\n\n\n\n\n\nEasy.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Raster Data Narrative</span>"
    ]
  },
  {
    "objectID": "raster_narrative.html#raster-operations",
    "href": "raster_narrative.html#raster-operations",
    "title": "9  Raster Data Narrative",
    "section": "9.8 Raster Operations",
    "text": "9.8 Raster Operations\nOK, so now we can make and show a raster but what about doing some operations? A raster is just a matrix decorated with more geospatial information. This allows us to do normal R like data manipulations on the underlying data.\nConsider the following question.\n\nWhat are the parts of Baja California that are within 100m of the elevation of site named San Francisquito (sfran)?\n\nTo answer this, we have the following general outline of operations.\n\nFind the coordinates of the site named sfran\n\nExtract the elevation from the alt raster that is within 100m (+/-) of that site.\nPlot the whole baja data as a background\n\nOverlay all the locations within that elevation band.\n\nTo do this we will use both the alt and the beetles data objects.\nFirst, we find out the coordinates of the site.\n\nsfran &lt;- beetles$geometry[ beetles$Site == \"sfran\"]\nsfran\n\nGeometry set for 1 feature \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -112.964 ymin: 27.3632 xmax: -112.964 ymax: 27.3632\nGeodetic CRS:  WGS 84\n\n\nPOINT (-112.964 27.3632)\n\n\nNow, we need to figure out what the value of elevation in the alt raster is at this site. This can be done with the extract() function from the raster library.\nHowever, the this function doesn’t work directly with sf objects so we need to cast it into a Spatial object1. Fortunatly, that is a pretty easy coercion.\n\nraster::extract(alt, as(sfran,\"Spatial\") ) \n\n[1] 305\n\n\n\nWarning: in the above code, I used the function extract() to extract the data from the alt raster for the coordinate of the target locale. However, there is also an extract() function that has been brought in from the dplyr library (as part of tidyverse). In this file, I loaded library(raster) before library(tidyverse) and as such the dplyr::extract() function has overridden the one from raster—they cannot both be available. As a consequence, I use the full name of the function with package::function when I call it as raster::extract() to remove all ambiguity. If I had not, I got a message saying something like, Error in UseMethod(\"extract_\") : no applicable method for 'extract_' applied to an object of class \"c('RasterLayer', 'Raster', 'BasicRaster')\". Now, I know there is an extract() function in raster so this is the dead giveaway that it has been overwritten by a subsequent library call.\n\n\n9.8.1 Option 1 - Manipulate the Raster\nTo work on a raster directly, we can access the values within it using the values() function (I know, these statistican/programmers are quite cleaver).\nSo, to make a copy and make only the values that are +/- 100m of sfran we can.\n\nalt_band &lt;- alt\nvalues( alt_band )[ values(alt_band) &lt;= 205 ] &lt;- NA\nvalues( alt_band )[ values(alt_band) &gt;= 405 ] &lt;- NA\nalt_band\n\nclass      : RasterLayer \ndimensions : 960, 840, 806400  (nrow, ncol, ncell)\nresolution : 0.008333333, 0.008333333  (x, y)\nextent     : -116, -109, 22, 30  (xmin, xmax, ymin, ymax)\ncrs        : +proj=longlat +datum=WGS84 +no_defs \nsource     : memory\nnames      : alt_22 \nvalues     : 206, 404  (min, max)\n\n\nThen we can plot overlay plots of each (notice how I hid the legend for the first alt raster).\n\nplot( alt, col=\"gray\", legend=FALSE, xlab=\"Longitude\", ylab=\"Latitude\")\nplot( alt_band, add=TRUE )\n\n\n\n\n\n\n\n\n\n\n9.8.2 Option 2 - Manipulate the Data Frames\nWe can also proceed by relying upon the data.frame objects representing the elevation. So let’s go back to our the alt.df object and use that in combination with a filter and plot both data.frame objects (the outline of the landscape in gray and the elevation range as a gradient). I then overlay the beetle data with the ratios as sizes and label the locales with ggrepel. Notice here that you can use the sf::geometry object from beetles if you pass it through the st_coordinates function as a statistical tranform making it regular coordinates and not sf objects (yes this is kind of a trick and hack but KEEP IT HANDY!).\n\nlibrary( ggrepel )\nalt.df %&gt;%\n  filter( Elevation &gt;= 205,\n          Elevation &lt;= 405) %&gt;%\n  ggplot() + \n  geom_raster( aes( x = Longitude,\n                    y = Latitude),\n               fill = \"gray80\", \n               data=alt.df ) + \n  geom_raster( aes( x = Longitude,\n                    y = Latitude, \n                    fill = Elevation ) ) + \n  scale_fill_gradient2( low = \"darkolivegreen\",\n                        mid = \"yellow\",\n                        high = \"brown\", \n                        midpoint = 305 ) +\n  geom_sf( aes(size=MFRatio), \n           alpha=0.5, \n           color=\"dodgerblue3\", \n           data=beetles) +\n  geom_text_repel( aes( label = Site,\n                        geometry = geometry),\n                   data = beetles,\n                   stat = \"sf_coordinates\", \n                   size = 4, \n                   color = \"dodgerblue4\") + \n  coord_sf() + \n  theme_minimal() \n\nWarning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not\ngive correct results for longitude/latitude data\n\n\n\n\n\n\n\n\n\nVery nice indeed.\n\nplot(r)\nclick(r)\n\n\n\n\n\n\n\n\nNULL",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Raster Data Narrative</span>"
    ]
  },
  {
    "objectID": "raster_narrative.html#footnotes",
    "href": "raster_narrative.html#footnotes",
    "title": "9  Raster Data Narrative",
    "section": "",
    "text": "A Spatial object is from the sp library. This is an older library that is still used by some. It is a robust library but it is put together in a slightly different way that complicates situations a bit, which is not why we are covering it in this topic.↩︎",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Raster Data Narrative</span>"
    ]
  },
  {
    "objectID": "text_narrative.html",
    "href": "text_narrative.html",
    "title": "10  Text Based Data",
    "section": "",
    "text": "10.1 Topic\nThis quick section will focus on the text—or, more aptly, character—data type. We commonly run across this as narrative or designations such as site names, locations, other bits of information that we need to",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Text Based Data</span>"
    ]
  },
  {
    "objectID": "text_narrative.html#data-types",
    "href": "text_narrative.html#data-types",
    "title": "10  Text Based Data",
    "section": "10.2 Data Types",
    "text": "10.2 Data Types\n\nx &lt;- \"Rodney\"\ny &lt;- 'Dyer'\n\nYou could use either single or double quotes to define a character type de novo—both work just fine. Having two of them is really helpful when you want to use one of the quote symbols inside the data.\n\nz &lt;- 'Bob Marley once said, \"It is a foolish dog that barks at a passing bird\"'\nz\n\n[1] \"Bob Marley once said, \\\"It is a foolish dog that barks at a passing bird\\\"\"\n\n\nBut notice that when you print it out to the terminal (or in the output to your Quarto chunck), it uses the backslash-double quote format. It also show up if you use print\n\nprint(z)\n\n[1] \"Bob Marley once said, \\\"It is a foolish dog that barks at a passing bird\\\"\"\n\n\nBut not when you cat it:\n\ncat(z)\n\nBob Marley once said, \"It is a foolish dog that barks at a passing bird\"\n\n\nThis is called escaping a special character. And it is a valid way to embed a quoting character into a sequence.\n\nw &lt;- \"\\\"Learning R is Fun,\\\" said Rodney.\"\ncat(w)\n\n\"Learning R is Fun,\" said Rodney.\n\n\nThere are other special characters that you will run across such as:\n\nThe Tab character, \\t\nThe New Line character \\n\nThe Return character \\r. This is becoming obsolete, in the “olden days” it was used with new line when we were making a transition from the manual typewriter where if you think about the action of using a typewriter, you need to advance a line AND return the carrage—the part that makes the letters on the paper—to the beginning of the line. That is why you sometimes see CR for on the return key. Windows used this convention and you may run across it still form peole who use that platform as \\r\\n. Mostly it is just yet another annoyance from some Windows software.\n\nTo see more, visit ?\"'\" in R.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Text Based Data</span>"
    ]
  },
  {
    "objectID": "text_narrative.html#the-stringr-library",
    "href": "text_narrative.html#the-stringr-library",
    "title": "10  Text Based Data",
    "section": "10.3 The stringr Library",
    "text": "10.3 The stringr Library\nAnother joy from the tidyverse folks is the stringr library that has made things a bit easier in handling string data. As usual, there is a cheatsheet linked in the assets on this topic.\n\nlibrary( tidyverse )",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Text Based Data</span>"
    ]
  },
  {
    "objectID": "text_narrative.html#the-verbs",
    "href": "text_narrative.html#the-verbs",
    "title": "10  Text Based Data",
    "section": "10.4 The ’Verbs”",
    "text": "10.4 The ’Verbs”\nWhen dealing with text, there are some basic verbs that we should recognize as fundamental actions that you’ll apply across a wide variety of situations. For text data, these include:\n\nCreating new/composite text.\nFinding content inside a string.\nDeleting content within a string\nReplacing content in a string with some new character value.\nManipulating content in a string.\n\n\n10.4.1 Creating\nWe’ve already seen how to create a single string, here is how we can smush (yes that is a technical term) together several kinds of data.\n\npaste( \"This\",\"is\",\"fun\")\n\n[1] \"This is fun\"\n\n\nYou can also mix-and-match different data types, as long as they can be coerced into a string type (which all data types can).\n\nnum &lt;- 42\npaste(\"It is\", TRUE, \"that my favorite number is\", num, \".\")\n\n[1] \"It is TRUE that my favorite number is 42 .\"\n\n\nWhen we work with character data, we need to realize that from the context of indexing, such as when we use a vector or data.frame, the sequence of characters is all one object.\n\nlength(z)\n\n[1] 1\n\n\nEven if it is made up of several characters. If we are interested subsequences within the string, we need to ask more specifically about the string length, not the variable length.\n\nstr_length( z )\n\n[1] 72\n\n\nThere are times when we need to paste more than a couple of individual items together.\n\na &lt;- 1:10\npaste( a )\n\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\"\n\npaste( a, sep=\", \")\n\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\"\n\npaste( a, collapse=\", \")\n\n[1] \"1, 2, 3, 4, 5, 6, 7, 8, 9, 10\"\n\n\nas separate columns\n\nb &lt;- LETTERS[1:10]\nc &lt;- rnorm(10,12, 1)\npaste( a,b,c, sep = \"-\" )\n\n [1] \"1-A-11.655491929423\"   \"2-B-12.6533172316792\"  \"3-C-12.1969742426239\" \n [4] \"4-D-12.0084204747289\"  \"5-E-10.6731052888775\"  \"6-F-11.3675794145171\" \n [7] \"7-G-11.3411542132602\"  \"8-H-11.3603619910682\"  \"9-I-12.2844262556829\" \n[10] \"10-J-11.8478551962621\"\n\n\nA stringr version is also available—with fewer keystrokes!\n\nstr_c( a, collapse=\", \" )\n\n[1] \"1, 2, 3, 4, 5, 6, 7, 8, 9, 10\"\n\n\nand\n\nstr_c( a,b,c)\n\n [1] \"1A11.655491929423\"   \"2B12.6533172316792\"  \"3C12.1969742426239\" \n [4] \"4D12.0084204747289\"  \"5E10.6731052888775\"  \"6F11.3675794145171\" \n [7] \"7G11.3411542132602\"  \"8H11.3603619910682\"  \"9I12.2844262556829\" \n[10] \"10J11.8478551962621\"\n\nstr_c( a,b,c, sep=\"-\")\n\n [1] \"1-A-11.655491929423\"   \"2-B-12.6533172316792\"  \"3-C-12.1969742426239\" \n [4] \"4-D-12.0084204747289\"  \"5-E-10.6731052888775\"  \"6-F-11.3675794145171\" \n [7] \"7-G-11.3411542132602\"  \"8-H-11.3603619910682\"  \"9-I-12.2844262556829\" \n[10] \"10-J-11.8478551962621\"\n\n\n\n\n10.4.2 Finding\nFinding text may be done in a few ways.\n\ncat(z)\n\nBob Marley once said, \"It is a foolish dog that barks at a passing bird\"\n\n\nWe can ask if:\n\nA particular sequence of characters exist in the string (TRUE/FALSE).\n\n\nstr_detect(z, \"Marley\")\n\n[1] TRUE\n\nstr_detect(z, \"marley\") # case sensitive\n\n[1] FALSE\n\n\n\nWe can ask for the number of times a sequences shows up in a string.\n\n\nstr_count(z, \"a\")\n\n[1] 8\n\n\n\nWe can ask where the first occurance of a subsequence of characters starts at:\n\n\nstr_locate( z, \"dog\")\n\n     start end\n[1,]    40  42\n\n\n\nWe can find all occurences of a substring.\n\n\nstr_locate_all( z, \"a\")\n\n[[1]]\n     start end\n[1,]     6   6\n[2,]    18  18\n[3,]    30  30\n[4,]    46  46\n[5,]    50  50\n[6,]    55  55\n[7,]    58  58\n[8,]    61  61\n\n\n\nIf we know the location of a substring, you can extract it. Here I use the negative for the second index, which is treated as “second from the end” of the string.\n\n\nstr_sub(z, 24, -2)\n\n[1] \"It is a foolish dog that barks at a passing bird\"\n\n\n\nIf we have several character objects in a vector, we can find the subset that contains a specific sequence.\n\n\ncharacter_vec &lt;- c(w,x,y,z)\ncharacter_vec\n\n[1] \"\\\"Learning R is Fun,\\\" said Rodney.\"                                       \n[2] \"Rodney\"                                                                    \n[3] \"Dyer\"                                                                      \n[4] \"Bob Marley once said, \\\"It is a foolish dog that barks at a passing bird\\\"\"\n\n\n\nstr_detect( character_vec, \"r\")\n\n[1]  TRUE FALSE  TRUE  TRUE\n\n\nHowever, it is case sensitive\n\nstr_detect( character_vec, \"R\")\n\n[1]  TRUE  TRUE FALSE FALSE\n\n\n\n\n10.4.3 Deleting\nThis is an easy one, if we want to remove one (the first occurence of) an item,\n\nstr_remove(z,\"dog\")\n\n[1] \"Bob Marley once said, \\\"It is a foolish  that barks at a passing bird\\\"\"\n\n\nOr all of them.\n\nstr_remove_all(z, \"a\")\n\n[1] \"Bob Mrley once sid, \\\"It is  foolish dog tht brks t  pssing bird\\\"\"\n\n\nWe can also remove compoennts by truncation\n\nstr_trunc( character_vec , 20)\n\n[1] \"\\\"Learning R is Fu...\" \"Rodney\"                \"Dyer\"                 \n[4] \"Bob Marley once s...\" \n\n\n\n\n10.4.4 Replacing\nThere are times when we are wanting to take some component within a string and replace it with another one—independent of the location of the item to be replaced within the string.\n\ncat( str_replace(z, \"Bob Marley\", \"Rodney\") )\n\nRodney once said, \"It is a foolish dog that barks at a passing bird\"\n\n\nIf we do know the location (character location) and size (str_length) of what we are replacing, then we can use those numerical values direction.\n\nstr_sub(z, 1, 10)\n\n[1] \"Bob Marley\"\n\n\n\n\n10.4.5 Manipulating\n\nMaking the string all lower case.\n\n\nstr_to_lower(z)\n\n[1] \"bob marley once said, \\\"it is a foolish dog that barks at a passing bird\\\"\"\n\n\n\nMaking it all uppercase.\n\n\nstr_to_upper(z)\n\n[1] \"BOB MARLEY ONCE SAID, \\\"IT IS A FOOLISH DOG THAT BARKS AT A PASSING BIRD\\\"\"\n\n\n\nCreating Title Case text.\n\n\nstr_to_title(z)\n\n[1] \"Bob Marley Once Said, \\\"It Is A Foolish Dog That Barks At A Passing Bird\\\"\"\n\n\n\nCapitalizing it as if it were a sentence.\n\n\nstr_to_sentence( \"this is getting a bit old, isn't it?\")\n\n[1] \"This is getting a bit old, isn't it?\"\n\n\n\ntmp &lt;- str_to_sentence(\"rodney exclaimed, \\\"but it doesn't know about internal quoted sentence fragments!\\\" and then sat down.\") \ncat(tmp)\n\nRodney exclaimed, \"but it doesn't know about internal quoted sentence fragments!\" And then sat down.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Text Based Data</span>"
    ]
  },
  {
    "objectID": "text_narrative.html#regular-expressions",
    "href": "text_narrative.html#regular-expressions",
    "title": "10  Text Based Data",
    "section": "11.1 Regular Expressions",
    "text": "11.1 Regular Expressions\nA regular expression, or regex is a concise language used for detecting and describing patterns found in language. An entire course could be taught on the use of regex but here we’ll only spend enough time on it so that you know some kind of magic exists in the universe and can explore it if you need to in the future.\nFor this example, I’m going to use some text data that I have been playing with regarding curriculum development.\n\nlibrary( readr )\nurl &lt;- \"https://raw.githubusercontent.com/DyerlabTeaching/Textual-Data/refs/heads/main/data/ENVSclasses.txt?token=GHSAT0AAAAAACWO27UIA46V72P7DBZEP5EKZYZFFXQ\"\nread_lines( url ) -&gt; envs\n\nThis goes out and grabs the data, and reads it in as a vector of type character.\n\nclass( envs )\n\n[1] \"character\"\n\n\nIf we take a look at it, we can see these are the listings for the undergraduate courses in Environmental Studies at VCU.\n\nhead(envs,17)\n\n [1] \"ENVS 101. Introduction to Environmental Studies I. 3 Hours.\"                \n [2] \"Semester course; 3 lecture hours. 3 credits. Enrollment is restricted to\"   \n [3] \"environmental studies majors. Study of contemporary issues related to\"      \n [4] \"environmental studies including sustainability, biological conservation,\"   \n [5] \"global change and an overview of the core earth systems.\"                   \n [6] \"ENVS 102. Introduction to Environmental Studies II. 3 Hours.\"               \n [7] \"Semester course; 3 lecture hours. 3 credits. Prerequisite: ENVS 101 or\"     \n [8] \"permission of instructor. Enrollment is restricted to environmental studies\"\n [9] \"majors. Studies of contemporary issues related to government policy and\"    \n[10] \"environmental issues at local to international scales.\"                     \n[11] \"886 Undergraduate courses\"                                                  \n[12] \"ENVS 105. Physical Geology. 3 Hours.\"                                       \n[13] \"Semester course; 3 lecture hours. 3 credits. A descriptive approach to\"     \n[14] \"physical geology dealing with the history and structure of the earth,\"      \n[15] \"catastrophic events and geology as it relates to the contemporary\"          \n[16] \"environment. An optional laboratory, ENVZ 105, may be taken with this\"      \n[17] \"course.\"                                                                    \n\n\nThere are a couple of things to notice:\n\nThe lines are short and the entry for each course is spread across several lines.\n\nEach course has a 4-letter code, a 3-digit number, a title, and then ends with the number of hours for the class.\nThere are five lines necessary to describe ENVS 101 but six for ENVS 105.\nLine 11 appears to be a page number and page heading and not part of any course description.\n\nLet’s say we wanted to extract some information about the course number, name, and number of hours from these data. This subset of data only has 262 line of text but if we were looking at all the courses at VCU, we would be faced with 25,945 lines of text! It could be done by hand but… that does not scale too well and I’ve got a lot better things to do than spend a year working on this simple task.\n\n11.1.1 Matching\nLet’s start by matching. Let’s look at what we did above and see if there are any tools we can use.\nWe do know that str_detect() will give us a TRUE/FALSE for any match. Let’s try that and take a look at the results.\n\nidx &lt;- str_detect(envs,\"ENVS\")\nhead( envs[idx] )\n\n[1] \"ENVS 101. Introduction to Environmental Studies I. 3 Hours.\"           \n[2] \"ENVS 102. Introduction to Environmental Studies II. 3 Hours.\"          \n[3] \"Semester course; 3 lecture hours. 3 credits. Prerequisite: ENVS 101 or\"\n[4] \"ENVS 105. Physical Geology. 3 Hours.\"                                  \n[5] \"ENVS 201. Earth System Science. 3 Hours.\"                              \n[6] \"ENVS 222. Electronic Portfolios. 1 Hour.\"                              \n\n\nOK, except that line 3 isn’t a title line, it just has an ENVS in it.\nMoveover, it also assumes that we are going to only be using ENVS but if we look at the end of the data set, we see that the lab courses in Environmental Studies are encoded as ENVZ and these will be totally ignored. Moreover, we would need to know, a priori, what all the program codes were before we started if we were going to take this approach.\n\ntail( envs )\n\n[1] \"Laboratory exercises coordinated with ENVS 335 lectures.\"                 \n[2] \"ENVZ 401. Meteorology and Climatology Laboratory. 1 Hour.\"                \n[3] \"Semester course; 3 laboratory hours. 1 credit. Pre- or corequisite:\"      \n[4] \"ENVS 401. A series of laboratory and field experiments designed to\"       \n[5] \"quantify the elements of weather and climate and to interpret their local\"\n[6] \"temporal and spatial variations.\"                                         \n\n\nUsing regex we can define a character pattern to look for. Let’s start by just taking the first line of text and using that to learn about pattern matching.\n\nenvs101 &lt;- envs[1]\nenvs101\n\n[1] \"ENVS 101. Introduction to Environmental Studies I. 3 Hours.\"\n\n\nThe stringr library has a helper function that allows us to see what parts of a string are being matched by a specific pattern. This function is str_view() and it colors and puts into angle brackets, the part that is matched.\nSo, looking for the characters ENVS looks like:\n\nstr_view(envs101,\"ENVS\")\n\n[1] │ &lt;ENVS&gt; 101. Introduction to Environmental Studies I. 3 Hours.\n\n\nand looking for 101 yields.\n\nstr_view( envs101, \"101\")\n\n[1] │ ENVS &lt;101&gt;. Introduction to Environmental Studies I. 3 Hours.\n\n\nIf ther is no match, nothing is returned:\n\nstr_view( envs101, \"Rodney\")\n\nand if many things are matched, it will highlight each of them.\n\nstr_view( envs101, \"o\")\n\n[1] │ ENVS 101. Intr&lt;o&gt;ducti&lt;o&gt;n t&lt;o&gt; Envir&lt;o&gt;nmental Studies I. 3 H&lt;o&gt;urs.\n\n\nSo, let’s get more general and look for patterns. These patterns are encoded using square brackets.\n\nMatching on any digit, which is defined as [:digit:].\n\n\nstr_view( envs101, \"[:digit:]\")\n\n[1] │ ENVS &lt;1&gt;&lt;0&gt;&lt;1&gt;. Introduction to Environmental Studies I. &lt;3&gt; Hours.\n\n\n\nMatching any non-numeric character, [:alpha:]\n\n\nstr_view( envs101, \"[:alpha:]\")\n\n[1] │ &lt;E&gt;&lt;N&gt;&lt;V&gt;&lt;S&gt; 101. &lt;I&gt;&lt;n&gt;&lt;t&gt;&lt;r&gt;&lt;o&gt;&lt;d&gt;&lt;u&gt;&lt;c&gt;&lt;t&gt;&lt;i&gt;&lt;o&gt;&lt;n&gt; &lt;t&gt;&lt;o&gt; &lt;E&gt;&lt;n&gt;&lt;v&gt;&lt;i&gt;&lt;r&gt;&lt;o&gt;&lt;n&gt;&lt;m&gt;&lt;e&gt;&lt;n&gt;&lt;t&gt;&lt;a&gt;&lt;l&gt; &lt;S&gt;&lt;t&gt;&lt;u&gt;&lt;d&gt;&lt;i&gt;&lt;e&gt;&lt;s&gt; &lt;I&gt;. 3 &lt;H&gt;&lt;o&gt;&lt;u&gt;&lt;r&gt;&lt;s&gt;.\n\n\n\nMatching punctuation, [:punct:]\n\n\nstr_view( envs101, \"[:punct:]\")\n\n[1] │ ENVS 101&lt;.&gt; Introduction to Environmental Studies I&lt;.&gt; 3 Hours&lt;.&gt;\n\n\n\nWe can also specify the case of the punctuation.\n\n\nstr_view( envs101, \"[:lower:]\")\n\n[1] │ ENVS 101. I&lt;n&gt;&lt;t&gt;&lt;r&gt;&lt;o&gt;&lt;d&gt;&lt;u&gt;&lt;c&gt;&lt;t&gt;&lt;i&gt;&lt;o&gt;&lt;n&gt; &lt;t&gt;&lt;o&gt; E&lt;n&gt;&lt;v&gt;&lt;i&gt;&lt;r&gt;&lt;o&gt;&lt;n&gt;&lt;m&gt;&lt;e&gt;&lt;n&gt;&lt;t&gt;&lt;a&gt;&lt;l&gt; S&lt;t&gt;&lt;u&gt;&lt;d&gt;&lt;i&gt;&lt;e&gt;&lt;s&gt; I. 3 H&lt;o&gt;&lt;u&gt;&lt;r&gt;&lt;s&gt;.\n\nstr_view( envs101, \"[:upper:]\")\n\n[1] │ &lt;E&gt;&lt;N&gt;&lt;V&gt;&lt;S&gt; 101. &lt;I&gt;ntroduction to &lt;E&gt;nvironmental &lt;S&gt;tudies &lt;I&gt;. 3 &lt;H&gt;ours.\n\n\n\nOr even spaces\n\n\nstr_view( envs101, \"[:space:]\")\n\n[1] │ ENVS&lt; &gt;101.&lt; &gt;Introduction&lt; &gt;to&lt; &gt;Environmental&lt; &gt;Studies&lt; &gt;I.&lt; &gt;3&lt; &gt;Hours.\n\n\n\n\n11.1.2 Combining Matches\nThat is helpful in some cases. But now we can start combining these things.\n\nLet’s mix a pattern and a fixed set of characters.\n\n\nstr_view( envs101, \"[:digit:] Hours\")\n\n[1] │ ENVS 101. Introduction to Environmental Studies I. &lt;3 Hours&gt;.\n\n\n\nHow about multiple patterns.\n\n\nstr_view( envs101, \"[:upper:][:space:][:digit:]\")\n\n[1] │ ENV&lt;S 1&gt;01. Introduction to Environmental Studies I. 3 Hours.\n\n\n\nOr multiples of the same pattern. To have the exact number of items, use a single number enclosed in curly brackets right after ther pattern. Here we are matching 4-upper case digits.\n\n\nstr_view(envs101, \"[:upper:]{4}\")\n\n[1] │ &lt;ENVS&gt; 101. Introduction to Environmental Studies I. 3 Hours.\n\n\nWe could also match those followed by a space and three numbers\n\nstr_view( envs101, \"[:upper:]{4}[:space:][:digit:]{3}\")\n\n[1] │ &lt;ENVS 101&gt;. Introduction to Environmental Studies I. 3 Hours.\n\n\n\nWe can generalize this a bit by asking for “zero or one” or “zero or more”—IMHO this is a terrible thing to match as a single thing.\n\n\nstr_view( envs101, \"[:punct:]?\")\n\n[1] │ &lt;&gt;E&lt;&gt;N&lt;&gt;V&lt;&gt;S&lt;&gt; &lt;&gt;1&lt;&gt;0&lt;&gt;1&lt;.&gt;&lt;&gt; &lt;&gt;I&lt;&gt;n&lt;&gt;t&lt;&gt;r&lt;&gt;o&lt;&gt;d&lt;&gt;u&lt;&gt;c&lt;&gt;t&lt;&gt;i&lt;&gt;o&lt;&gt;n&lt;&gt; &lt;&gt;t&lt;&gt;o&lt;&gt; &lt;&gt;E&lt;&gt;n&lt;&gt;v&lt;&gt;i&lt;&gt;r&lt;&gt;o&lt;&gt;n&lt;&gt;m&lt;&gt;e&lt;&gt;n&lt;&gt;t&lt;&gt;a&lt;&gt;l&lt;&gt; &lt;&gt;S&lt;&gt;t&lt;&gt;u&lt;&gt;d&lt;&gt;i&lt;&gt;e&lt;&gt;s&lt;&gt; &lt;&gt;I&lt;.&gt;&lt;&gt; &lt;&gt;3&lt;&gt; &lt;&gt;H&lt;&gt;o&lt;&gt;u&lt;&gt;r&lt;&gt;s&lt;.&gt;&lt;&gt;\n\nstr_view( envs101, \"[:punct:]*\")\n\n[1] │ &lt;&gt;E&lt;&gt;N&lt;&gt;V&lt;&gt;S&lt;&gt; &lt;&gt;1&lt;&gt;0&lt;&gt;1&lt;.&gt;&lt;&gt; &lt;&gt;I&lt;&gt;n&lt;&gt;t&lt;&gt;r&lt;&gt;o&lt;&gt;d&lt;&gt;u&lt;&gt;c&lt;&gt;t&lt;&gt;i&lt;&gt;o&lt;&gt;n&lt;&gt; &lt;&gt;t&lt;&gt;o&lt;&gt; &lt;&gt;E&lt;&gt;n&lt;&gt;v&lt;&gt;i&lt;&gt;r&lt;&gt;o&lt;&gt;n&lt;&gt;m&lt;&gt;e&lt;&gt;n&lt;&gt;t&lt;&gt;a&lt;&gt;l&lt;&gt; &lt;&gt;S&lt;&gt;t&lt;&gt;u&lt;&gt;d&lt;&gt;i&lt;&gt;e&lt;&gt;s&lt;&gt; &lt;&gt;I&lt;.&gt;&lt;&gt; &lt;&gt;3&lt;&gt; &lt;&gt;H&lt;&gt;o&lt;&gt;u&lt;&gt;r&lt;&gt;s&lt;.&gt;&lt;&gt;\n\n\nBut for our purposes, we can ask for “one or more” by appending a plus sign.\n\nstr_view( envs101, \"[:digit:]+\")\n\n[1] │ ENVS &lt;101&gt;. Introduction to Environmental Studies I. &lt;3&gt; Hours.\n\n\nor match to digits, punctuation, or letters (one or more) using the shorthand .+ notation. It is the period that matches anything and the plus that does one or more of them.\n\nstr_view( envs101, \".+\")\n\n[1] │ &lt;ENVS 101. Introduction to Environmental Studies I. 3 Hours.&gt;\n\n\nThis becomes helpful a bit later when we are trying to anchor the course designation (e.g., ENVS 101) at the start, ONE OR MORE THING IN THE MIDDLE, and then the end of the line with the number of hours (e.g., 3 Hours.)\n\n\n11.1.3 Positional Matching\nWhere the items is in the string may be of importance to us. For example, consider another line in the data that specifies ENVS101 as a prerequisite. It does not come from a line of text that is the title of the course, it just also happens to match the 4 uppercase letters, space, and three digits pattern.\n\nstr_view( envs[37], \"[:upper:]{4}[:space:][:digit:]{3}\")\n\n[1] │ Semester course; 2 lecture hours. 2 credits. Prerequisites: &lt;ENVS 101&gt;\n\n\nThis is where the position in the line may be of interest.\n\nTo match things that occur at the beginning of the string, we prepend the pattern with the carat symbol.\n\n\nstr_view( envs101, \"^[:upper:]{4}[:space:][:digit:]{3}\")\n\n[1] │ &lt;ENVS 101&gt;. Introduction to Environmental Studies I. 3 Hours.\n\n\nThis matches our first line but not a line where this pattern does not occur in the beginning of the string.\n\nstr_view( envs[37], \"^[:upper:]{4}[:space:][:digit:]{3}\")\n\n\nFor the end of the string, we use the dollar sign to anchor it to the end.\n\n\nstr_view( envs[37], \"[:upper:]{4}[:space:][:digit:]{3}$\")\n\n[1] │ Semester course; 2 lecture hours. 2 credits. Prerequisites: &lt;ENVS 101&gt;\n\n\nwhich is not in the envs101 string\n\nstr_view( envs101, \"[:upper:]{4}[:space:][:digit:]{3}$\")\n\n\n\n11.1.4 Putting it Together\nSo, now let’s pull this all together and see if we can match: 1. The course designation at the start of the line. 2. The title 3. The end of the line with the number of hours.\n\nstr_view( envs101, \"^[:upper:]{4} [:digit:]{3}.*[:digit:] Hours.$\")\n\n[1] │ &lt;ENVS 101. Introduction to Environmental Studies I. 3 Hours.&gt;\n\n\nSo, there is one little extension—and this a common theme we’ve run across—and that has to do with the fact that programmers are a bit lazy. You can subsititue, the square-bracket-colon-word-colon-square-bracket for the following:\n\n[0-9] is shorthand for [:digits:].\n[a-z] is shorthand for [:lower:].\n\n[A-Z] is shorthand for [:upper:].\n\nWhich means that we can go from\n\npattern &lt;- \"^[:upper:]{4} [:digit:]{3}.*[:digit:] Hours.$\"\n\nto this\n\npattern &lt;- \"^[A-Z]{4} [0-9]{3}.+[0-9] Hours.$\"\n\nas our seach pattern.\n\nstr_view( envs101, pattern )\n\n[1] │ &lt;ENVS 101. Introduction to Environmental Studies I. 3 Hours.&gt;\n\n\nInstead of asking a single line, we need to apply this expressions to each line in the data an return the ones that match. For this, we can use grepl, which returns a TRUE/FALSE on matching. The tricky thing here is that the pattern comes first and the vector second (reverse from what we’ve been using.)\nSo for our data, we see\n\ngrepl(pattern, envs )\n\n  [1]  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE\n [13] FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n [25] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE\n [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE\n [49] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE\n [61] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE\n [73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [85] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE\n [97] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE\n[109] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE\n[121] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE\n[133] FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE\n[145] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE\n[157] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE\n[169] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE\n[181] FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE\n[193] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[205] FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n[217] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE\n[229] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE\n[241]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[253] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\nWhich is great as we can use it for extracting the lines of the data that have our information. Let’s use the grepl as indices and grab the titles from envs using it.\n\nidx &lt;- grepl( pattern, envs )\nenvs[idx] -&gt; titles\ntitles\n\n [1] \"ENVS 101. Introduction to Environmental Studies I. 3 Hours.\"     \n [2] \"ENVS 102. Introduction to Environmental Studies II. 3 Hours.\"    \n [3] \"ENVS 105. Physical Geology. 3 Hours.\"                            \n [4] \"ENVS 201. Earth System Science. 3 Hours.\"                        \n [5] \"ENVS 260. Outdoor Leadership. 3 Hours.\"                          \n [6] \"ENVS 265. Paths to Environmental Leadership. 2 Hours.\"           \n [7] \"ENVS 291. Special Topics in Environmental Studies. 1-4 Hours.\"   \n [8] \"ENVS 300. Sustainable Societies: James River Basin. 3 Hours.\"    \n [9] \"ENVS 301. Introduction to Meteorology. 3 Hours.\"                 \n[10] \"ENVS 310. Introduction to Oceanography. 3 Hours.\"                \n[11] \"ENVS 311. Politics of the Environment. 3 Hours.\"                 \n[12] \"ENVS 315. Energy and the Environment. 3 Hours.\"                  \n[13] \"ENVS 321. Cartography. 3 Hours.\"                                 \n[14] \"ENVS 330. Environmental Pollution. 3 Hours.\"                     \n[15] \"ENVS 332. Environmental Management. 3 Hours.\"                    \n[16] \"ENVS 335. Environmental Geology. 3 Hours.\"                       \n[17] \"ENVS 343. Data Literacy. 4 Hours.\"                               \n[18] \"ENVS 355. Water. 3 Hours.\"                                       \n[19] \"ENVS 360. Outdoor Programming and Event Management. 3 Hours.\"    \n[20] \"ENVS 361. Outdoor Team Building and Group Facilitation. 3 Hours.\"\n[21] \"ENVS 368. Nature Writing. 3 Hours.\"                              \n[22] \"ENVS 370. Applications of Conservation Science. 3 Hours.\"        \n[23] \"ENVS 391. Special Topics in Environmental Studies. 1-4 Hours.\"   \n[24] \"ENVS 401. Meteorology and Climatology. 3 Hours.\"                 \n[25] \"ENVS 411. Oceanography. 3 Hours.\"                                \n[26] \"ENVS 421. Environmental Data Visualization. 3 Hours.\"            \n[27] \"ENVS 430. Invasive Species Management. 3 Hours.\"                 \n[28] \"ENVS 460. Wilderness First Responder. 3 Hours.\"                  \n[29] \"ENVS 461. Wilderness Policy and Practice. 3 Hours.\"              \n[30] \"ENVS 490. Research Seminar in Environmental Studies. 3 Hours.\"   \n[31] \"ENVS 491. Topics in Environmental Studies. 1-4 Hours.\"           \n[32] \"ENVS 492. Independent Study. 1-3 Hours.\"                         \n[33] \"ENVS 493. Environmental Studies Internship. 1-3 Hours.\"          \n[34] \"ENVS 499. Environmental Studies Capstone Experience. 0 Hours.\"   \n\n\nThat looks pretty good! We are almost there.\n\nraw &lt;- str_split(titles, pattern=\"\\\\.\", simplify = TRUE)\ndim(raw)\n\n[1] 34  4\n\nhead(raw)\n\n     [,1]       [,2]                                        [,3]       [,4]\n[1,] \"ENVS 101\" \" Introduction to Environmental Studies I\"  \" 3 Hours\" \"\"  \n[2,] \"ENVS 102\" \" Introduction to Environmental Studies II\" \" 3 Hours\" \"\"  \n[3,] \"ENVS 105\" \" Physical Geology\"                         \" 3 Hours\" \"\"  \n[4,] \"ENVS 201\" \" Earth System Science\"                     \" 3 Hours\" \"\"  \n[5,] \"ENVS 260\" \" Outdoor Leadership\"                       \" 3 Hours\" \"\"  \n[6,] \"ENVS 265\" \" Paths to Environmental Leadership\"        \" 2 Hours\" \"\"  \n\n\nOK, so now we can easily grab these columns and put them into a data.frame.\n\nprogram &lt;- str_split( raw[,1], pattern=\" \", simplify=TRUE)[,1]\nprogram \n\n [1] \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\"\n[11] \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\"\n[21] \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\"\n[31] \"ENVS\" \"ENVS\" \"ENVS\" \"ENVS\"\n\n\n\ncode &lt;- str_split( raw[,1], pattern=\" \", simplify=TRUE)[,2]\ncode &lt;- as.numeric( code )\ncode \n\n [1] 101 102 105 201 260 265 291 300 301 310 311 315 321 330 332 335 343 355 360\n[20] 361 368 370 391 401 411 421 430 460 461 490 491 492 493 499\n\n\n\ntitle &lt;- raw[,2]\ntitle\n\n [1] \" Introduction to Environmental Studies I\"     \n [2] \" Introduction to Environmental Studies II\"    \n [3] \" Physical Geology\"                            \n [4] \" Earth System Science\"                        \n [5] \" Outdoor Leadership\"                          \n [6] \" Paths to Environmental Leadership\"           \n [7] \" Special Topics in Environmental Studies\"     \n [8] \" Sustainable Societies: James River Basin\"    \n [9] \" Introduction to Meteorology\"                 \n[10] \" Introduction to Oceanography\"                \n[11] \" Politics of the Environment\"                 \n[12] \" Energy and the Environment\"                  \n[13] \" Cartography\"                                 \n[14] \" Environmental Pollution\"                     \n[15] \" Environmental Management\"                    \n[16] \" Environmental Geology\"                       \n[17] \" Data Literacy\"                               \n[18] \" Water\"                                       \n[19] \" Outdoor Programming and Event Management\"    \n[20] \" Outdoor Team Building and Group Facilitation\"\n[21] \" Nature Writing\"                              \n[22] \" Applications of Conservation Science\"        \n[23] \" Special Topics in Environmental Studies\"     \n[24] \" Meteorology and Climatology\"                 \n[25] \" Oceanography\"                                \n[26] \" Environmental Data Visualization\"            \n[27] \" Invasive Species Management\"                 \n[28] \" Wilderness First Responder\"                  \n[29] \" Wilderness Policy and Practice\"              \n[30] \" Research Seminar in Environmental Studies\"   \n[31] \" Topics in Environmental Studies\"             \n[32] \" Independent Study\"                           \n[33] \" Environmental Studies Internship\"            \n[34] \" Environmental Studies Capstone Experience\"   \n\n\n\ncredits &lt;- raw[,3]\ncredits &lt;- str_replace(credits, \"Hours\", \"\")\ncredits &lt;- str_trim( credits )\ncredits\n\n [1] \"3\"   \"3\"   \"3\"   \"3\"   \"3\"   \"2\"   \"1-4\" \"3\"   \"3\"   \"3\"   \"3\"   \"3\"  \n[13] \"3\"   \"3\"   \"3\"   \"3\"   \"4\"   \"3\"   \"3\"   \"3\"   \"3\"   \"3\"   \"1-4\" \"3\"  \n[25] \"3\"   \"3\"   \"3\"   \"3\"   \"3\"   \"3\"   \"1-4\" \"1-3\" \"1-3\" \"0\"  \n\n\n\ndata.frame( program, code, title, credits) -&gt; df \nsummary(df)\n\n   program               code          title             credits         \n Length:34          Min.   :101.0   Length:34          Length:34         \n Class :character   1st Qu.:303.2   Class :character   Class :character  \n Mode  :character   Median :349.0   Mode  :character   Mode  :character  \n                    Mean   :346.4                                        \n                    3rd Qu.:418.5                                        \n                    Max.   :499.0                                        \n\n\n\nhead(df)\n\n  program code                                     title credits\n1    ENVS  101   Introduction to Environmental Studies I       3\n2    ENVS  102  Introduction to Environmental Studies II       3\n3    ENVS  105                          Physical Geology       3\n4    ENVS  201                      Earth System Science       3\n5    ENVS  260                        Outdoor Leadership       3\n6    ENVS  265         Paths to Environmental Leadership       2",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Text Based Data</span>"
    ]
  },
  {
    "objectID": "text_narrative.html#extra-credit",
    "href": "text_narrative.html#extra-credit",
    "title": "10  Text Based Data",
    "section": "11.2 Extra Credit",
    "text": "11.2 Extra Credit\nLet’s close by doing something fun. Let’s make a wordcloud of the titles from ENVS classes.\n\nstr_split( title, \" \")\n\n[[1]]\n[1] \"\"              \"Introduction\"  \"to\"            \"Environmental\"\n[5] \"Studies\"       \"I\"            \n\n[[2]]\n[1] \"\"              \"Introduction\"  \"to\"            \"Environmental\"\n[5] \"Studies\"       \"II\"           \n\n[[3]]\n[1] \"\"         \"Physical\" \"Geology\" \n\n[[4]]\n[1] \"\"        \"Earth\"   \"System\"  \"Science\"\n\n[[5]]\n[1] \"\"           \"Outdoor\"    \"Leadership\"\n\n[[6]]\n[1] \"\"              \"Paths\"         \"to\"            \"Environmental\"\n[5] \"Leadership\"   \n\n[[7]]\n[1] \"\"              \"Special\"       \"Topics\"        \"in\"           \n[5] \"Environmental\" \"Studies\"      \n\n[[8]]\n[1] \"\"            \"Sustainable\" \"Societies:\"  \"James\"       \"River\"      \n[6] \"Basin\"      \n\n[[9]]\n[1] \"\"             \"Introduction\" \"to\"           \"Meteorology\" \n\n[[10]]\n[1] \"\"             \"Introduction\" \"to\"           \"Oceanography\"\n\n[[11]]\n[1] \"\"            \"Politics\"    \"of\"          \"the\"         \"Environment\"\n\n[[12]]\n[1] \"\"            \"Energy\"      \"and\"         \"the\"         \"Environment\"\n\n[[13]]\n[1] \"\"            \"Cartography\"\n\n[[14]]\n[1] \"\"              \"Environmental\" \"Pollution\"    \n\n[[15]]\n[1] \"\"              \"Environmental\" \"Management\"   \n\n[[16]]\n[1] \"\"              \"Environmental\" \"Geology\"      \n\n[[17]]\n[1] \"\"         \"Data\"     \"Literacy\"\n\n[[18]]\n[1] \"\"      \"Water\"\n\n[[19]]\n[1] \"\"            \"Outdoor\"     \"Programming\" \"and\"         \"Event\"      \n[6] \"Management\" \n\n[[20]]\n[1] \"\"             \"Outdoor\"      \"Team\"         \"Building\"     \"and\"         \n[6] \"Group\"        \"Facilitation\"\n\n[[21]]\n[1] \"\"        \"Nature\"  \"Writing\"\n\n[[22]]\n[1] \"\"             \"Applications\" \"of\"           \"Conservation\" \"Science\"     \n\n[[23]]\n[1] \"\"              \"Special\"       \"Topics\"        \"in\"           \n[5] \"Environmental\" \"Studies\"      \n\n[[24]]\n[1] \"\"            \"Meteorology\" \"and\"         \"Climatology\"\n\n[[25]]\n[1] \"\"             \"Oceanography\"\n\n[[26]]\n[1] \"\"              \"Environmental\" \"Data\"          \"Visualization\"\n\n[[27]]\n[1] \"\"           \"Invasive\"   \"Species\"    \"Management\"\n\n[[28]]\n[1] \"\"           \"Wilderness\" \"First\"      \"Responder\" \n\n[[29]]\n[1] \"\"           \"Wilderness\" \"Policy\"     \"and\"        \"Practice\"  \n\n[[30]]\n[1] \"\"              \"Research\"      \"Seminar\"       \"in\"           \n[5] \"Environmental\" \"Studies\"      \n\n[[31]]\n[1] \"\"              \"Topics\"        \"in\"            \"Environmental\"\n[5] \"Studies\"      \n\n[[32]]\n[1] \"\"            \"Independent\" \"Study\"      \n\n[[33]]\n[1] \"\"              \"Environmental\" \"Studies\"       \"Internship\"   \n\n[[34]]\n[1] \"\"              \"Environmental\" \"Studies\"       \"Capstone\"     \n[5] \"Experience\"   \n\nstr_split( title, \" \", simplify=TRUE)\n\n      [,1] [,2]            [,3]          [,4]            [,5]           \n [1,] \"\"   \"Introduction\"  \"to\"          \"Environmental\" \"Studies\"      \n [2,] \"\"   \"Introduction\"  \"to\"          \"Environmental\" \"Studies\"      \n [3,] \"\"   \"Physical\"      \"Geology\"     \"\"              \"\"             \n [4,] \"\"   \"Earth\"         \"System\"      \"Science\"       \"\"             \n [5,] \"\"   \"Outdoor\"       \"Leadership\"  \"\"              \"\"             \n [6,] \"\"   \"Paths\"         \"to\"          \"Environmental\" \"Leadership\"   \n [7,] \"\"   \"Special\"       \"Topics\"      \"in\"            \"Environmental\"\n [8,] \"\"   \"Sustainable\"   \"Societies:\"  \"James\"         \"River\"        \n [9,] \"\"   \"Introduction\"  \"to\"          \"Meteorology\"   \"\"             \n[10,] \"\"   \"Introduction\"  \"to\"          \"Oceanography\"  \"\"             \n[11,] \"\"   \"Politics\"      \"of\"          \"the\"           \"Environment\"  \n[12,] \"\"   \"Energy\"        \"and\"         \"the\"           \"Environment\"  \n[13,] \"\"   \"Cartography\"   \"\"            \"\"              \"\"             \n[14,] \"\"   \"Environmental\" \"Pollution\"   \"\"              \"\"             \n[15,] \"\"   \"Environmental\" \"Management\"  \"\"              \"\"             \n[16,] \"\"   \"Environmental\" \"Geology\"     \"\"              \"\"             \n[17,] \"\"   \"Data\"          \"Literacy\"    \"\"              \"\"             \n[18,] \"\"   \"Water\"         \"\"            \"\"              \"\"             \n[19,] \"\"   \"Outdoor\"       \"Programming\" \"and\"           \"Event\"        \n[20,] \"\"   \"Outdoor\"       \"Team\"        \"Building\"      \"and\"          \n[21,] \"\"   \"Nature\"        \"Writing\"     \"\"              \"\"             \n[22,] \"\"   \"Applications\"  \"of\"          \"Conservation\"  \"Science\"      \n[23,] \"\"   \"Special\"       \"Topics\"      \"in\"            \"Environmental\"\n[24,] \"\"   \"Meteorology\"   \"and\"         \"Climatology\"   \"\"             \n[25,] \"\"   \"Oceanography\"  \"\"            \"\"              \"\"             \n[26,] \"\"   \"Environmental\" \"Data\"        \"Visualization\" \"\"             \n[27,] \"\"   \"Invasive\"      \"Species\"     \"Management\"    \"\"             \n[28,] \"\"   \"Wilderness\"    \"First\"       \"Responder\"     \"\"             \n[29,] \"\"   \"Wilderness\"    \"Policy\"      \"and\"           \"Practice\"     \n[30,] \"\"   \"Research\"      \"Seminar\"     \"in\"            \"Environmental\"\n[31,] \"\"   \"Topics\"        \"in\"          \"Environmental\" \"Studies\"      \n[32,] \"\"   \"Independent\"   \"Study\"       \"\"              \"\"             \n[33,] \"\"   \"Environmental\" \"Studies\"     \"Internship\"    \"\"             \n[34,] \"\"   \"Environmental\" \"Studies\"     \"Capstone\"      \"Experience\"   \n      [,6]         [,7]          \n [1,] \"I\"          \"\"            \n [2,] \"II\"         \"\"            \n [3,] \"\"           \"\"            \n [4,] \"\"           \"\"            \n [5,] \"\"           \"\"            \n [6,] \"\"           \"\"            \n [7,] \"Studies\"    \"\"            \n [8,] \"Basin\"      \"\"            \n [9,] \"\"           \"\"            \n[10,] \"\"           \"\"            \n[11,] \"\"           \"\"            \n[12,] \"\"           \"\"            \n[13,] \"\"           \"\"            \n[14,] \"\"           \"\"            \n[15,] \"\"           \"\"            \n[16,] \"\"           \"\"            \n[17,] \"\"           \"\"            \n[18,] \"\"           \"\"            \n[19,] \"Management\" \"\"            \n[20,] \"Group\"      \"Facilitation\"\n[21,] \"\"           \"\"            \n[22,] \"\"           \"\"            \n[23,] \"Studies\"    \"\"            \n[24,] \"\"           \"\"            \n[25,] \"\"           \"\"            \n[26,] \"\"           \"\"            \n[27,] \"\"           \"\"            \n[28,] \"\"           \"\"            \n[29,] \"\"           \"\"            \n[30,] \"Studies\"    \"\"            \n[31,] \"\"           \"\"            \n[32,] \"\"           \"\"            \n[33,] \"\"           \"\"            \n[34,] \"\"           \"\"            \n\nas.vector( str_split( title, \" \", simplify=TRUE) ) -&gt; words\n\nwords &lt;- words[ str_length(words) &gt; 0 ]\n\nwords &lt;- sort( words )\nwords\n\n  [1] \"and\"           \"and\"           \"and\"           \"and\"          \n  [5] \"and\"           \"Applications\"  \"Basin\"         \"Building\"     \n  [9] \"Capstone\"      \"Cartography\"   \"Climatology\"   \"Conservation\" \n [13] \"Data\"          \"Data\"          \"Earth\"         \"Energy\"       \n [17] \"Environment\"   \"Environment\"   \"Environmental\" \"Environmental\"\n [21] \"Environmental\" \"Environmental\" \"Environmental\" \"Environmental\"\n [25] \"Environmental\" \"Environmental\" \"Environmental\" \"Environmental\"\n [29] \"Environmental\" \"Environmental\" \"Environmental\" \"Event\"        \n [33] \"Experience\"    \"Facilitation\"  \"First\"         \"Geology\"      \n [37] \"Geology\"       \"Group\"         \"I\"             \"II\"           \n [41] \"in\"            \"in\"            \"in\"            \"in\"           \n [45] \"Independent\"   \"Internship\"    \"Introduction\"  \"Introduction\" \n [49] \"Introduction\"  \"Introduction\"  \"Invasive\"      \"James\"        \n [53] \"Leadership\"    \"Leadership\"    \"Literacy\"      \"Management\"   \n [57] \"Management\"    \"Management\"    \"Meteorology\"   \"Meteorology\"  \n [61] \"Nature\"        \"Oceanography\"  \"Oceanography\"  \"of\"           \n [65] \"of\"            \"Outdoor\"       \"Outdoor\"       \"Outdoor\"      \n [69] \"Paths\"         \"Physical\"      \"Policy\"        \"Politics\"     \n [73] \"Pollution\"     \"Practice\"      \"Programming\"   \"Research\"     \n [77] \"Responder\"     \"River\"         \"Science\"       \"Science\"      \n [81] \"Seminar\"       \"Societies:\"    \"Special\"       \"Special\"      \n [85] \"Species\"       \"Studies\"       \"Studies\"       \"Studies\"      \n [89] \"Studies\"       \"Studies\"       \"Studies\"       \"Studies\"      \n [93] \"Studies\"       \"Study\"         \"Sustainable\"   \"System\"       \n [97] \"Team\"          \"the\"           \"the\"           \"to\"           \n[101] \"to\"            \"to\"            \"to\"            \"to\"           \n[105] \"Topics\"        \"Topics\"        \"Topics\"        \"Visualization\"\n[109] \"Water\"         \"Wilderness\"    \"Wilderness\"    \"Writing\"      \n\n\nWe need to have the data in the format of\nWord | Count\nso let’s use our dplyr skills.\n\ndata.frame( words, count = 1 ) |&gt; \n  mutate( word = factor( words ) ) |&gt; \n  group_by( word ) |&gt;\n  summarize( freq = sum( count )) |&gt; \n  arrange( -freq ) -&gt; tdm \n\ntdm \n\n# A tibble: 62 × 2\n   word           freq\n   &lt;fct&gt;         &lt;dbl&gt;\n 1 Environmental    13\n 2 Studies           8\n 3 and               5\n 4 to                5\n 5 in                4\n 6 Introduction      4\n 7 Management        3\n 8 Outdoor           3\n 9 Topics            3\n10 Data              2\n# ℹ 52 more rows\n\n\n\nif( !require( wordcloud ) ) { \n  install.packages(\"wordcloud\")\n  install.packages(\"wordcloud2\")  # for more fancy\n} \n\nLoading required package: wordcloud\n\n\nLoading required package: RColorBrewer\n\n\n\nlibrary( wordcloud )\nwordcloud( words = tdm$word, \n           freq = tdm$freq )\n\n\n\n\n\n\n\n\n\nwordcloud( words = tdm$word, \n           freq = tdm$freq,\n           scale=c(3.5,0.25) ) \n\n\n\n\n\n\n\n\n\nwordcloud( words = tdm$word, \n           freq = tdm$freq,\n           scale=c(3.5,0.25),\n           min.freq = 1 ) \n\n\n\n\n\n\n\n\n\nwordcloud( words = tdm$word, \n           freq = tdm$freq,\n           scale=c(3.5,0.25),\n           min.freq = 2 ) \n\n\n\n\n\n\n\n\n\nwordcloud( words = tdm$word, \n           freq = tdm$freq,\n           scale=c(3.5,0.25),\n           min.freq = 2,\n           colors = brewer.pal(8,\"Dark2\")) \n\n\n\n\n\n\n\n\n\nlibrary( wordcloud2 )\nwordcloud2(data = tdm)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Text Based Data</span>"
    ]
  },
  {
    "objectID": "index.html#workflow-data-analysis",
    "href": "index.html#workflow-data-analysis",
    "title": "ENVS543.2024",
    "section": "Workflow & Data Analysis",
    "text": "Workflow & Data Analysis\nTo understand data analytics, one needs to recognize the entire workflow. Below is a brief graphical depiction of how analysis actually works—in the real world. In this class, we will work on all of these components using the open-source R language.\n\nCollect: Getting data from an external source into a format that you can use is often the most time-consuming step in the analysis. The content of this class will provide training in data import from local, online, and database sources.\n\nVisualize: Visualizing data is key to understanding. In the image below, notice that the variables X and Y in all the displayed data sets have equivalent means, standard deviations, and correlation up to 2 decimal places! We will emphasize visualization, both static and dynamic, throughout this class.\n\nTransform: Pulling data into your analysis ecosystem is not sufficient. Often the data need to be reformatted and reconfigured before it is actually usable.\n\nModel: The application of models to subsets of data is often the step that takes the least amount of time and effort. However, the application of a model to data is not the endpoint. The model must be visualized and, many times, the underlying data or derivate data must be transformed and submitted to subsequent models.\n\nCommunicate: The effort we put into research and analyses is meaningless without effective communication of your data and findings to a broad audience. Here, we will focus on how to develop effective data communication strategies and formats.\n\n\n\n\nNormal Workflow",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "ENVS543.2024",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nThe purpose of this course is to help you build your data skills and to develop a foundational understanding upon which subsequent courses will build. The overarching goal here is to develop a working knowledge of the R statistical computing language and enough proficiency to import raw data and then iterate through the visualization, manipulation, and analysis steps in the creation of output that is easily communicated to a scientific audience.\nThe content of this course is built upon the following general student learning objectives (SLO):\n\nSLO 1: Identity, manipulate, and summarize numerical, categorical, ordinal, logical, date, string, and spatial data types.\nSLO 2: Create habits and took the knowledge to support reproducible research.\nSLO 3: Create an informative and effective graphical display of various data types of suitable quality for inclusion in published manuscripts.\nSLO 4: Effectively choose appropriate statistical models based on the types of data at hand and the questions being addressed.\nSLO 5: Demonstrate a general understanding of spatial data types and the creation of both appropriate static and dynamic maps.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#course-content-assessment",
    "href": "index.html#course-content-assessment",
    "title": "ENVS543.2024",
    "section": "Course Content & Assessment",
    "text": "Course Content & Assessment\nThis course is designed as a sequence of individual, stand-alone modules. Each is self-contained and includes a lecture, slides, a larger narrative document, a video demonstration, and an assessment.\n\n\n\n\n\n\n\n\nDeliverable\nDetails\nSLO\n\n\n\n\nWelcome & Logistics\nSetting up the logistics for the class, getting R, RStudio, and Quarto installed on each of your machines, and getting a tour of the IDE.\nNA\n\n\nGit, Github, & Markdown\nEstablish a functional working knowledge of git as a collaborative tool for reproducible research and begin working with Markdown as an output for data analysis.\n2\n\n\nData Types & Containers\nUnderstanding the fundamental data types and containers within R and how to import, work with easily, and export raw data.\n1, 2\n\n\nTidyverse\nData manipulation. Like a boss.\n1, 2\n\n\nBasic Graphics\nNormal graphics built into the R system.\n2, 3\n\n\nGraphics that DON’T suck\nHello publication quality graphics, using the grammar of graphics approach\n2,3\n\n\nPoints, Lines, & Polygons\nSpatial data in vector format vectors\n3, 5\n\n\nRaster Data\nContinuously distributed spatial data\n3, 5\n\n\nStatistical Confidence\nBase understanding of statistical inferences and the properties of sampled data\n1,2,4\n\n\nBinomial Inferences\nAnalyses based upon expectations.\n4\n\n\nCategorical~f(Categorical)\nContingency table and categorical count data\n4\n\n\nContinuous~f(Categorical)\nAnalysis of Variance (or equality of means)\n4\n\n\nContinuous~f(Continuous)\nCorrelation & Regression approaches\n4\n\n\nCategorical~f(Continuous)\nLogistic regression\n4",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#logistics",
    "href": "index.html#logistics",
    "title": "ENVS543.2024",
    "section": "Logistics",
    "text": "Logistics\n\nCourse Instructor: Professor Rodney Dyer\nEmail: rjdyer@vcu.edu\nWebpage: rodneydyer.com.",
    "crumbs": [
      "Preface"
    ]
  }
]